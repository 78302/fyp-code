{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cf06a8e",
   "metadata": {},
   "source": [
    "# APC Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4070a9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "# import torchvision\n",
    "\n",
    "INPUT_SIZE = 40\n",
    "HIDDEN_SIZE = 512  # units inside the lstm\n",
    "# DROP_RATE = 0.2  # drop-out rate\n",
    "LAYERS = 1  # number of lstm layers, will be increased to 4\n",
    "\n",
    "\n",
    "class toy_lstm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(toy_lstm, self).__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=HIDDEN_SIZE,\n",
    "            num_layers=LAYERS,\n",
    "#             dropout=DROP_RATE,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(HIDDEN_SIZE, 40)  # fully connected layer\n",
    "        self.h_s = None\n",
    "        self.h_c = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        r_out, (h_s, h_c) = self.rnn(x)\n",
    "        output = self.fc(r_out)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58a25b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kaldiark\n",
    "\n",
    "# # Read data index from the total scp file\n",
    "\n",
    "# count = 0\n",
    "\n",
    "# with open('./data/raw_fbank_train_si284.1.scp', 'rb') as scp_file:  # use '../remote/data/wsj/fbank/' replace '/data/'\n",
    "#     lines = scp_file.readlines()\n",
    "#     for line in lines: # line is like b'4avc040p /home/htang2/kaldi/wsj/fbank/raw_fbank_train_si284.10.ark:2769059\\n'\n",
    "#         temp = str(line).split()[1]\n",
    "#         print(temp)\n",
    "#         file_loc = temp.split(':')[0][28:]  # ark file path; keep [18:]\n",
    "#         pointer = temp.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the utterance\n",
    "#         print(file_loc)\n",
    "#         print(pointer)\n",
    "\n",
    "#         # According to the file name and pointer to get the matrix\n",
    "#         with open('./data' + file_loc, 'rb') as ark_file:  # use '../remote/data' + file_loc replace './data/' + file_loc\n",
    "#             ark_file.seek(int(pointer))\n",
    "#             utt_mat = kaldiark.parse_feat_matrix(ark_file)\n",
    "#             print(utt_mat.shape)  \n",
    "        \n",
    "#         count = count + 1\n",
    "#         if count > 10:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6242663c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: [1/60], train_loss: 185.335281, valid_loss: 107.390554, best_valid_loss: 107.390554, lr: 0.0050000\n",
      "iter: [2/60], train_loss: 118.975380, valid_loss: 66.732348, best_valid_loss: 66.732348, lr: 0.0050000\n",
      "iter: [3/60], train_loss: 74.532879, valid_loss: 37.939902, best_valid_loss: 37.939902, lr: 0.0050000\n",
      "iter: [4/60], train_loss: 42.338984, valid_loss: 21.579492, best_valid_loss: 21.579492, lr: 0.0050000\n",
      "iter: [5/60], train_loss: 22.557779, valid_loss: 16.344495, best_valid_loss: 16.344495, lr: 0.0050000\n",
      "iter: [6/60], train_loss: 13.814932, valid_loss: 19.274874, best_valid_loss: 16.344495, lr: 0.0050000\n",
      "iter: [7/60], train_loss: 13.090472, valid_loss: 26.252875, best_valid_loss: 16.344495, lr: 0.0050000\n",
      "iter: [8/60], train_loss: 16.465832, valid_loss: 33.299493, best_valid_loss: 16.344495, lr: 0.0050000\n",
      "iter: [9/60], train_loss: 20.382216, valid_loss: 37.702118, best_valid_loss: 16.344495, lr: 0.0050000\n",
      "iter: [10/60], train_loss: 22.570373, valid_loss: 38.490917, best_valid_loss: 16.344495, lr: 0.0050000\n",
      "iter: [11/60], train_loss: 22.241153, valid_loss: 35.775551, best_valid_loss: 16.344495, lr: 0.0050000\n",
      "iter: [12/60], train_loss: 19.916075, valid_loss: 31.479891, best_valid_loss: 16.344495, lr: 0.0050000\n",
      "iter: [13/60], train_loss: 17.029061, valid_loss: 26.915883, best_valid_loss: 16.344495, lr: 0.0050000\n",
      "iter: [14/60], train_loss: 14.421190, valid_loss: 22.884276, best_valid_loss: 16.344495, lr: 0.0050000\n",
      "iter: [15/60], train_loss: 12.644375, valid_loss: 19.857562, best_valid_loss: 16.344495, lr: 0.0050000\n",
      "iter: [16/60], train_loss: 11.865329, valid_loss: 17.857606, best_valid_loss: 16.344495, lr: 0.0050000\n",
      "iter: [17/60], train_loss: 11.926786, valid_loss: 16.824047, best_valid_loss: 16.344495, lr: 0.0050000\n",
      "iter: [18/60], train_loss: 12.327363, valid_loss: 16.303992, best_valid_loss: 16.303992, lr: 0.0050000\n",
      "iter: [19/60], train_loss: 12.682915, valid_loss: 16.042475, best_valid_loss: 16.042475, lr: 0.0050000\n",
      "iter: [20/60], train_loss: 12.778398, valid_loss: 15.939068, best_valid_loss: 15.939068, lr: 0.0050000\n",
      "iter: [21/60], train_loss: 12.592671, valid_loss: 16.005062, best_valid_loss: 15.939068, lr: 0.0050000\n",
      "iter: [22/60], train_loss: 12.240403, valid_loss: 16.286565, best_valid_loss: 15.939068, lr: 0.0050000\n",
      "iter: [23/60], train_loss: 11.877368, valid_loss: 16.791387, best_valid_loss: 15.939068, lr: 0.0050000\n",
      "iter: [24/60], train_loss: 11.618578, valid_loss: 17.454460, best_valid_loss: 15.939068, lr: 0.0050000\n",
      "iter: [25/60], train_loss: 11.500014, valid_loss: 18.150913, best_valid_loss: 15.939068, lr: 0.0050000\n",
      "iter: [26/60], train_loss: 11.487948, valid_loss: 18.741211, best_valid_loss: 15.939068, lr: 0.0050000\n",
      "iter: [27/60], train_loss: 11.517526, valid_loss: 19.120375, best_valid_loss: 15.939068, lr: 0.0050000\n",
      "iter: [28/60], train_loss: 11.533529, valid_loss: 19.247209, best_valid_loss: 15.939068, lr: 0.0050000\n",
      "iter: [29/60], train_loss: 11.512887, valid_loss: 19.144683, best_valid_loss: 15.939068, lr: 0.0050000\n",
      "iter: [30/60], train_loss: 11.463619, valid_loss: 18.878307, best_valid_loss: 15.939068, lr: 0.0050000\n",
      "iter: [31/60], train_loss: 11.426764, valid_loss: 18.840885, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [32/60], train_loss: 11.419742, valid_loss: 18.794208, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [33/60], train_loss: 11.411001, valid_loss: 18.740578, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [34/60], train_loss: 11.401130, valid_loss: 18.682035, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [35/60], train_loss: 11.390662, valid_loss: 18.620356, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [36/60], train_loss: 11.380048, valid_loss: 18.557067, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [37/60], train_loss: 11.369654, valid_loss: 18.493443, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [38/60], train_loss: 11.359757, valid_loss: 18.430542, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [39/60], train_loss: 11.350563, valid_loss: 18.369211, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [40/60], train_loss: 11.342200, valid_loss: 18.310118, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [41/60], train_loss: 11.334740, valid_loss: 18.253774, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [42/60], train_loss: 11.328201, valid_loss: 18.200551, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [43/60], train_loss: 11.322568, valid_loss: 18.150693, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [44/60], train_loss: 11.317795, valid_loss: 18.104359, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [45/60], train_loss: 11.313814, valid_loss: 18.061617, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [46/60], train_loss: 11.311796, valid_loss: 18.057674, best_valid_loss: 15.939068, lr: 0.0000500\n",
      "iter: [47/60], train_loss: 11.311505, valid_loss: 18.054000, best_valid_loss: 15.939068, lr: 0.0000500\n",
      "iter: [48/60], train_loss: 11.311231, valid_loss: 18.050543, best_valid_loss: 15.939068, lr: 0.0000500\n",
      "iter: [49/60], train_loss: 11.310972, valid_loss: 18.047269, best_valid_loss: 15.939068, lr: 0.0000500\n",
      "iter: [50/60], train_loss: 11.310726, valid_loss: 18.044142, best_valid_loss: 15.939068, lr: 0.0000500\n",
      "iter: [51/60], train_loss: 11.310491, valid_loss: 18.041143, best_valid_loss: 15.939068, lr: 0.0000500\n",
      "iter: [52/60], train_loss: 11.310265, valid_loss: 18.038245, best_valid_loss: 15.939068, lr: 0.0000500\n",
      "iter: [53/60], train_loss: 11.310047, valid_loss: 18.035432, best_valid_loss: 15.939068, lr: 0.0000500\n",
      "iter: [54/60], train_loss: 11.309836, valid_loss: 18.032693, best_valid_loss: 15.939068, lr: 0.0000500\n",
      "iter: [55/60], train_loss: 11.309631, valid_loss: 18.030011, best_valid_loss: 15.939068, lr: 0.0000500\n",
      "iter: [56/60], train_loss: 11.309430, valid_loss: 18.027380, best_valid_loss: 15.939068, lr: 0.0000500\n",
      "iter: [57/60], train_loss: 11.309235, valid_loss: 18.024790, best_valid_loss: 15.939068, lr: 0.0000500\n",
      "iter: [58/60], train_loss: 11.309043, valid_loss: 18.022238, best_valid_loss: 15.939068, lr: 0.0000500\n",
      "iter: [59/60], train_loss: 11.308856, valid_loss: 18.019716, best_valid_loss: 15.939068, lr: 0.0000500\n",
      "iter: [60/60], train_loss: 11.308671, valid_loss: 18.017221, best_valid_loss: 15.939068, lr: 0.0000500\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import kaldiark\n",
    "from apc import toy_lstm\n",
    "import glob\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # \n",
    "\n",
    "LEARNING_RATE = 0.005\n",
    "EPOCH = 60\n",
    "\n",
    "rnn = toy_lstm().to(device)  \n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LEARNING_RATE)  # optimize all parameters\n",
    "loss_func = nn.MSELoss()\n",
    "# Learning rate decay schedule\n",
    "mult_step_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                                           milestones=[EPOCH // 2, EPOCH // 4 * 3], gamma=0.1)\n",
    "\n",
    "# Predefine the prediction gap\n",
    "K = 2  # predefine the gap\n",
    "\n",
    "# Train + Dev\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "min_valid_loss = np.inf\n",
    "for i in range(EPOCH):\n",
    "    total_train_loss = []\n",
    "    rnn.train()  # Training\n",
    "    \n",
    "    # Use the total scp files\n",
    "    # Read data index from the total scp file\n",
    "    with open('./data/raw_fbank_train_si284.1.scp', 'rb') as scp_file:\n",
    "        lines = scp_file.readlines()\n",
    "        for line in lines[:2]:  # use 2 utt to test\n",
    "            temp = str(line).split()[1]\n",
    "            file_loc = temp.split(':')[0][28:]  # ark file path; keep [18:]\n",
    "            pointer = temp.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the utterance\n",
    "#             print(file_loc, pointer)\n",
    "\n",
    "            # According to the file name and pointer to get the matrix\n",
    "            with open('./data' + file_loc, 'rb') as ark_file:\n",
    "                ark_file.seek(int(pointer))\n",
    "                utt_mat = kaldiark.parse_feat_matrix(ark_file)\n",
    "            \n",
    "                utt_mat = np.expand_dims(utt_mat, axis=0)  # expand a new dimension as batch\n",
    "                utt_mat = torch.Tensor(utt_mat).to(device)   # change data to tensor\n",
    "                output = rnn(utt_mat[:, :-K, :])\n",
    "                \n",
    "#                 print(utt_mat.shape, output.shape)\n",
    "\n",
    "                loss = loss_func(output, utt_mat[:, K:, :])  # compute the difference\n",
    "                optimizer.zero_grad()  # clear gradients for this training step\n",
    "                loss.backward()  # back-prop\n",
    "                optimizer.step()  # gradients\n",
    "                total_train_loss.append(loss.item())\n",
    "        train_loss.append(np.mean(total_train_loss))\n",
    "    # print('train complete!')\n",
    "\n",
    "    total_valid_loss = []\n",
    "    rnn.eval()  # Validation\n",
    "    \n",
    "    # Use one of scp files\n",
    "    # Read data index from the total scp file\n",
    "    with open('./data/raw_fbank_train_si284.2.scp', 'rb') as scp_file:  # change 1 to dev \n",
    "        lines = scp_file.readlines()\n",
    "        for line in lines[:3]:\n",
    "            temp = str(line).split()[1]\n",
    "            file_loc = temp.split(':')[0][28:]  # ark file path; keep [18:]\n",
    "            pointer = temp.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the utterance\n",
    "\n",
    "            # According to the file name and pointer to get the matrix\n",
    "            with open('./data' + file_loc, 'rb') as ark_file:\n",
    "                ark_file.seek(int(pointer))\n",
    "                utt_mat = kaldiark.parse_feat_matrix(ark_file)\n",
    "            \n",
    "                utt_mat = np.expand_dims(utt_mat, axis=0)  # expand a new dimension as batch\n",
    "                utt_mat = torch.Tensor(utt_mat).to(device)   # change data to tensor\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    output = rnn(utt_mat[:, :-K, :])  # rnn output\n",
    "                    \n",
    "#                     print(utt_mat_mat.shape, output.shape)\n",
    "\n",
    "                loss = loss_func(output, utt_mat[:, K:, :])\n",
    "            total_valid_loss.append(loss.item())\n",
    "        valid_loss.append(np.mean(total_valid_loss))\n",
    "    # print('dev complete!')\n",
    "    \n",
    "    # save the net\n",
    "\n",
    "    min_valid_loss = np.min(valid_loss)\n",
    "    \n",
    "    if ((i + 1) % 10 == 0):\n",
    "        torch.save({'epoch': i + 1, 'state_dict': rnn.state_dict(), 'train_loss': train_loss,\n",
    "                    'valid_loss': valid_loss, 'optimizer': optimizer.state_dict()},\n",
    "                    './model/Epoch{:d}.pth.tar'.format((i + 1), min_valid_loss))\n",
    "    \n",
    "\n",
    "    # Log\n",
    "    log_string = ('iter: [{:d}/{:d}], train_loss: {:0.6f}, valid_loss: {:0.6f}, '\n",
    "                  'best_valid_loss: {:0.6f}, lr: {:0.7f}').format((i + 1), EPOCH,\n",
    "                                                                  train_loss[-1],\n",
    "                                                                  valid_loss[-1],\n",
    "                                                                  min_valid_loss,\n",
    "                                                                  optimizer.param_groups[0]['lr'])\n",
    "    mult_step_scheduler.step()  # 学习率更新\n",
    "    print(log_string)  # 打印日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e8eeb9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt  \n",
    "matplotlib.use('Agg')\n",
    "y = train_loss\n",
    "x = np.arange(0,len(train_loss))\n",
    "fig, ax = plt.subplots(figsize=(14,7))\n",
    "ax.plot(x,y,'r--',label='type1')\n",
    "\n",
    "ax.set_title('Loss',fontsize=18)\n",
    "ax.set_xlabel('epoch', fontsize=18,fontfamily = 'sans-serif',fontstyle='italic')\n",
    "ax.set_ylabel('loss', fontsize='x-large',fontstyle='oblique')\n",
    "ax.legend()\n",
    "\n",
    "plt.savefig(\"loss.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "adb3d3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path, model, optimizer):\n",
    "    \n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    return model, optimizer\n",
    "\n",
    "PATH = './model/Epoch60.pth.tar'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 对照-使用默认参数\n",
    "rnn_raw = toy_lstm().to(device)\n",
    "optimizer_raw = torch.optim.Adam(rnn.parameters(), lr=LEARNING_RATE)  # optimize all parameters\n",
    "\n",
    "# 使用预训练参数\n",
    "rnn_pretrain = toy_lstm().to(device)\n",
    "optimizer_pretrain = torch.optim.Adam(rnn.parameters(), lr=LEARNING_RATE)  # optimize all parameters\n",
    "rnn_pretrain, optimizer_pretrain = load_model(PATH, rnn_pretrain, optimizer_pretrain)\n",
    "\n",
    "rnn_pretrain.eval()\n",
    "rnn_raw.eval()\n",
    "\n",
    "# get 2 utt mats:\n",
    "# Predefine the prediction gap\n",
    "K = 2  # predefine the gap\n",
    "\n",
    "ori_mat = []\n",
    "pre_mat = []\n",
    "with open('./data/raw_fbank_train_si284.1.scp', 'rb') as scp_file:\n",
    "    lines = scp_file.readlines()\n",
    "    # for line in lines[:2]:  # use 1 utt to test\n",
    "    temp = str(lines[0]).split()[1]\n",
    "    file_loc = temp.split(':')[0][28:]  # ark file path; keep [18:]\n",
    "    pointer = temp.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the utterance\n",
    "\n",
    "    # According to the file name and pointer to get the matrix\n",
    "    with open('./data' + file_loc, 'rb') as ark_file:\n",
    "        ark_file.seek(int(pointer))\n",
    "        utt_mat = kaldiark.parse_feat_matrix(ark_file)\n",
    "            \n",
    "        utt_mat = np.expand_dims(utt_mat, axis=0)  # expand a new dimension as batch\n",
    "        utt_mat = torch.Tensor(utt_mat).to(device)   # change data to tensor\n",
    "        \n",
    "        output_raw = rnn_raw(utt_mat[:, :-K, :])\n",
    "        output_pretrain = rnn_pretrain(utt_mat[:, :-K, :])\n",
    "                \n",
    "        ori_mat.append(utt_mat[0, :-K, :])\n",
    "        pre_mat.append(output_raw[0])\n",
    "        pre_mat.append(output_pretrain[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fcfd1d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = ori_mat[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "11eb4c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = pre_mat[0].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f03e69c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = pre_mat[1].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "503f6f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Save Image Function\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = plt.gca()\n",
    "cax = plt.imshow(m1, cmap='viridis')\n",
    "# # set up colorbar\n",
    "# cbar = plt.colorbar(cax, extend='both', drawedges = False)\n",
    "# cbar.set_label('Intensity',size=36, weight =  'bold')\n",
    "# cbar.ax.tick_params( labelsize=18 )\n",
    "# cbar.minorticks_on()\n",
    "# # set up axis labels\n",
    "# ticks=np.arange(0,m1.shape[0],1)\n",
    "# ## For x ticks\n",
    "# plt.xticks(ticks, fontsize=12, fontweight = 'bold')\n",
    "# ax.set_xticklabels(ticks)\n",
    "# ## For y ticks\n",
    "# plt.yticks(ticks, fontsize=12, fontweight = 'bold')\n",
    "# ax.set_yticklabels(ticks)\n",
    "plt.savefig('origin.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "301b5680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Image Function\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = plt.gca()\n",
    "cax = plt.imshow(m2, cmap='viridis')\n",
    "plt.savefig('raw.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4f60ac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Image Function\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = plt.gca()\n",
    "cax = plt.imshow(m3, cmap='viridis')\n",
    "plt.savefig('pretrained.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2d8f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f8add9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae262ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84151745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.9013,  3.5482,  3.9370,  ..., 12.6050, 12.6487, 12.5332],\n",
      "        [ 3.8091,  3.2036,  3.6625,  ..., 12.8245, 12.6994, 12.1048],\n",
      "        [ 4.3622,  3.4333,  4.2115,  ..., 12.7971, 12.9021, 12.0844],\n",
      "        ...,\n",
      "        [ 4.1779,  3.2036,  3.3879,  ..., 12.6324, 12.7501, 11.7375],\n",
      "        [ 3.8091,  2.1698,  3.7997,  ..., 12.7971, 12.3445, 11.7579],\n",
      "        [ 3.3482,  3.0887,  3.3879,  ..., 13.0715, 13.1809, 12.4312]])\n",
      "tensor([[ 3.9013,  3.5482,  3.9370,  ..., 12.6050, 12.6487, 12.5332],\n",
      "        [ 3.8091,  3.2036,  3.6625,  ..., 12.8245, 12.6994, 12.1048],\n",
      "        [ 4.3622,  3.4333,  4.2115,  ..., 12.7971, 12.9021, 12.0844],\n",
      "        ...,\n",
      "        [ 3.9013,  4.3522,  3.1134,  ..., 12.8245, 12.6233, 12.3904],\n",
      "        [ 3.7170,  4.6968,  4.6233,  ..., 12.9343, 12.9528, 12.4108],\n",
      "        [ 4.1779,  3.2036,  3.3879,  ..., 12.6324, 12.7501, 11.7375]])\n",
      "tensor([[-0.0204, -0.0401,  0.1698,  ...,  0.0237, -0.0143,  0.0480],\n",
      "        [ 0.0033, -0.0277,  0.1911,  ...,  0.0355, -0.0017,  0.0486],\n",
      "        [ 0.0229,  0.0054,  0.2038,  ...,  0.0396,  0.0291,  0.0517],\n",
      "        ...,\n",
      "        [ 0.0650,  0.0404,  0.2205,  ...,  0.0443,  0.1243,  0.0175],\n",
      "        [ 0.0562,  0.0354,  0.2289,  ...,  0.0473,  0.1081,  0.0246],\n",
      "        [ 0.0705,  0.0546,  0.2297,  ...,  0.0468,  0.1078,  0.0308]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[ 7.1982,  7.3003,  7.7380,  ...,  8.3063,  8.5552,  8.2469],\n",
      "        [ 9.6438,  9.7859, 10.4431,  ..., 11.1874, 11.5854, 11.1365],\n",
      "        [10.0378, 10.1777, 10.8667,  ..., 11.6556, 12.0799, 11.6058],\n",
      "        ...,\n",
      "        [10.1030, 10.2439, 10.9385,  ..., 11.7354, 12.1617, 11.6827],\n",
      "        [10.1031, 10.2435, 10.9391,  ..., 11.7349, 12.1623, 11.6826],\n",
      "        [10.1047, 10.2435, 10.9370,  ..., 11.7358, 12.1616, 11.6829]],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(utt_mat[0])\n",
    "print(ori_mat[0])\n",
    "print(pre_mat[0])\n",
    "print(pre_mat[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eb6847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "147517be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['rnn.weight_ih_l0', 'rnn.weight_hh_l0', 'rnn.bias_ih_l0', 'rnn.bias_hh_l0', 'fc.weight', 'fc.bias'])\n",
      "<class 'collections.OrderedDict'>\n"
     ]
    }
   ],
   "source": [
    "load_dict = torch.load('./model/Epoch30.pth.tar')['state_dict']\n",
    "print(load_dict.keys())\n",
    "print(type(load_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6502385c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4b3339c",
   "metadata": {},
   "source": [
    "# Probing Task Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79a96264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "class classification_net(torch.nn.Module):  \n",
    "    def __init__(self, input_size, hidden_size, output_size):  \n",
    "        super(classification_net, self).__init__()  \n",
    "        self.hidden_layer = torch.nn.Linear(input_size, hidden_size)  \n",
    "        self.out = torch.nn.Linear(hidden_size, output_size)  \n",
    "    def forward(self, x):  \n",
    "        x = torch.relu(self.hidden_layer(x))  \n",
    "        x = self.out(x) \n",
    "        x = torch.nn.functional.softmax(x)  \n",
    "        return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fca39923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_net(\n",
      "  (hidden_layer): Linear(in_features=40, out_features=512, bias=True)\n",
      "  (out): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = classification_net(input_size=40, hidden_size=512, output_size=2)  \n",
    "print(net)  \n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.02)  \n",
    "loss_func = torch.nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a96e11c",
   "metadata": {},
   "source": [
    "One hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d8ee72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unk', 'aa', 'ae', 'ah', 'ao', 'aw', 'ay', 'b', 'ch', 'd', 'dh', 'eh', 'er', 'ey', 'f', 'g', 'hh', 'ih', 'iy', 'jh', 'k', 'l', 'm', 'n', 'ng', 'nsn', 'ow', 'oy', 'p', 'r', 's', 'sh', 'sil', 'spn', 't', 'th', 'uh', 'uw', 'v', 'w', 'y', 'z', 'zh']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open('./data/phones-unk.txt', 'r') as ph_file:\n",
    "    standard = ph_file.read().splitlines()\n",
    "    print(standard)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3c22e163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhou/anaconda3/envs/fyp/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: [1/20], train_loss: 3.763740, valid_loss: 3.774309, best_valid_loss: 3.774309, lr: 0.0010000\n",
      "iter: [2/20], train_loss: 3.781741, valid_loss: 3.774309, best_valid_loss: 3.774309, lr: 0.0010000\n",
      "iter: [3/20], train_loss: 3.754421, valid_loss: 3.716027, best_valid_loss: 3.716027, lr: 0.0010000\n",
      "iter: [4/20], train_loss: 3.724160, valid_loss: 3.716027, best_valid_loss: 3.716027, lr: 0.0010000\n",
      "iter: [5/20], train_loss: 3.724160, valid_loss: 3.716027, best_valid_loss: 3.716027, lr: 0.0010000\n",
      "iter: [6/20], train_loss: 3.724160, valid_loss: 3.716027, best_valid_loss: 3.716027, lr: 0.0010000\n",
      "iter: [7/20], train_loss: 3.724160, valid_loss: 3.716027, best_valid_loss: 3.716027, lr: 0.0010000\n",
      "iter: [8/20], train_loss: 3.724160, valid_loss: 3.716027, best_valid_loss: 3.716027, lr: 0.0010000\n",
      "iter: [9/20], train_loss: 3.724160, valid_loss: 3.716027, best_valid_loss: 3.716027, lr: 0.0010000\n",
      "iter: [10/20], train_loss: 3.737266, valid_loss: 3.778910, best_valid_loss: 3.716027, lr: 0.0010000\n",
      "iter: [11/20], train_loss: 3.771385, valid_loss: 3.778910, best_valid_loss: 3.716027, lr: 0.0001000\n",
      "iter: [12/20], train_loss: 3.771385, valid_loss: 3.778910, best_valid_loss: 3.716027, lr: 0.0001000\n",
      "iter: [13/20], train_loss: 3.771385, valid_loss: 3.778910, best_valid_loss: 3.716027, lr: 0.0001000\n",
      "iter: [14/20], train_loss: 3.771385, valid_loss: 3.778910, best_valid_loss: 3.716027, lr: 0.0001000\n",
      "iter: [15/20], train_loss: 3.771385, valid_loss: 3.778910, best_valid_loss: 3.716027, lr: 0.0001000\n",
      "iter: [16/20], train_loss: 3.771385, valid_loss: 3.778910, best_valid_loss: 3.716027, lr: 0.0000100\n",
      "iter: [17/20], train_loss: 3.771385, valid_loss: 3.778910, best_valid_loss: 3.716027, lr: 0.0000100\n",
      "iter: [18/20], train_loss: 3.771385, valid_loss: 3.778910, best_valid_loss: 3.716027, lr: 0.0000100\n",
      "iter: [19/20], train_loss: 3.771385, valid_loss: 3.778910, best_valid_loss: 3.716027, lr: 0.0000100\n",
      "iter: [20/20], train_loss: 3.771385, valid_loss: 3.778910, best_valid_loss: 3.716027, lr: 0.0000100\n"
     ]
    }
   ],
   "source": [
    "# para prep\n",
    "HIDDEN_SIZE = 40  # WILL BE USE 512\n",
    "OUTPUT_SIZE = 43\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCH = 20\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # \n",
    "\n",
    "# classifier use representation dimension as input size -- i.e. HIDDEN_SIZE\n",
    "classifier = classification_net(input_size=HIDDEN_SIZE, hidden_size=HIDDEN_SIZE, output_size=OUTPUT_SIZE).to(DEVICE)  \n",
    "# print(net)  \n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=LEARNING_RATE)  # optimize all parameters\n",
    "# Learning rate decay schedule\n",
    "mult_step_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                                           milestones=[EPOCH // 2, EPOCH // 4 * 3], gamma=0.1)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "import kaldiark\n",
    "bpali_file = open('./data/train-si284.bpali', 'rb')\n",
    "fbank_scp = open('./data/si284-0.9-train.fbank.scp', 'rb')\n",
    "fbank_lines = fbank_scp.readlines()\n",
    "\n",
    "\n",
    "# Train + Dev\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "min_valid_loss = np.inf\n",
    "for i in range(EPOCH):\n",
    "    total_train_loss = []\n",
    "    classifier.train()  # Training\n",
    "    \n",
    "    with open('./data/si284-0.9-train.bpali.scp', 'rb') as scp_file:\n",
    "        bpali_lines = scp_file.readlines()\n",
    "        for idx,line in enumerate(bpali_lines[:3]):\n",
    "            # Find the label\n",
    "            temp = str(line).split()[1]\n",
    "            pointer = temp.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the label\n",
    "            # Linux only has \\n\n",
    "            bpali_file.seek(int(pointer))\n",
    "            transcript = bpali_file.readline()\n",
    "            labels = str(transcript)[2:-3].split()\n",
    "#             print(str(transcript)[2:-3])\n",
    "\n",
    "            # Find the utterance\n",
    "            utt_line = fbank_lines[idx]\n",
    "            temp = str(utt_line).split()[1]\n",
    "            utt_file_loc = temp.split(':')[0][24:]  # ark file path; keep [14:]\n",
    "            utt_pointer = temp.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the utterance\n",
    "            # print(file_loc, pointer)\n",
    "            # According to the file name and pointer to get the matrix\n",
    "            with open('./data' + utt_file_loc, 'rb') as ark_file:\n",
    "                ark_file.seek(int(utt_pointer))\n",
    "                utt_mat = kaldiark.parse_feat_matrix(ark_file)\n",
    "                utt_mat = torch.Tensor(utt_mat).to(DEVICE)   # change data to tensor\n",
    "#                 utt_mat = np.expand_dims(utt_mat, axis=0)  # expand a new dimension as batch\n",
    "#             print(utt_mat.shape)\n",
    "\n",
    "                for idx,mat in enumerate(utt_mat):\n",
    "                    mat = torch.unsqueeze(mat, 0)\n",
    "                    x = mat.to(DEVICE)\n",
    "                    y = standard.index(labels[idx])\n",
    "                    y = torch.tensor([y], dtype=torch.long).to(DEVICE)\n",
    "                \n",
    "                    optimizer.zero_grad()\n",
    "                    output=classifier(x)\n",
    "                    loss=loss_func(output,y) \n",
    "                    \n",
    "                    loss.backward() \n",
    "                    optimizer.step() \n",
    "                    total_train_loss.append(loss.item())\n",
    "        train_loss.append(np.mean(total_train_loss))\n",
    "\n",
    "    total_valid_loss = []\n",
    "    classifier.eval()  # Validation\n",
    "    \n",
    "    with open('./data/si284-0.9-train.bpali.scp', 'rb') as scp_file:\n",
    "        bpali_lines = scp_file.readlines()\n",
    "        for idx,line in enumerate(bpali_lines[:1]):\n",
    "            # Find the label\n",
    "            temp = str(line).split()[1]\n",
    "            pointer = temp.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the label\n",
    "            # Linux only has \\n\n",
    "            bpali_file.seek(int(pointer))\n",
    "            transcript = bpali_file.readline()\n",
    "            labels = str(transcript)[2:-3].split()\n",
    "#             print(str(transcript)[2:-3])\n",
    "\n",
    "            # Find the utterance\n",
    "            utt_line = fbank_lines[idx]\n",
    "            temp = str(utt_line).split()[1]\n",
    "            utt_file_loc = temp.split(':')[0][24:]  # ark file path; keep [14:]\n",
    "            utt_pointer = temp.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the utterance\n",
    "            # print(file_loc, pointer)\n",
    "            # According to the file name and pointer to get the matrix\n",
    "            with open('./data' + utt_file_loc, 'rb') as ark_file:\n",
    "                ark_file.seek(int(utt_pointer))\n",
    "                utt_mat = kaldiark.parse_feat_matrix(ark_file)  \n",
    "                utt_mat = torch.Tensor(utt_mat).to(DEVICE)   # change data to tensor\n",
    "#                 utt_mat = np.expand_dims(utt_mat, axis=0)  # expand a new dimension as batch\n",
    "#             print(utt_mat.shape)\n",
    "\n",
    "                for idx,mat in enumerate(utt_mat):\n",
    "                    mat = torch.unsqueeze(mat, 0)\n",
    "                    x = mat.to(DEVICE)\n",
    "                    y = standard.index(labels[idx])\n",
    "                    y = torch.tensor([y], dtype=torch.long).to(DEVICE)\n",
    "                \n",
    "                    with torch.no_grad():\n",
    "                        output = classifier(x)\n",
    "                    loss=loss_func(output,y) \n",
    "                    total_valid_loss.append(loss.item())\n",
    "        valid_loss.append(np.mean(total_valid_loss))   \n",
    "    \n",
    "    # save the net\n",
    "\n",
    "    min_valid_loss = np.min(valid_loss)\n",
    "    \n",
    "    if ((i + 1) % 1 == 0):\n",
    "        torch.save({'epoch': i + 1, 'state_dict': classifier.state_dict(), 'train_loss': train_loss,\n",
    "                    'valid_loss': valid_loss, 'optimizer': optimizer.state_dict()},\n",
    "                    './model_classifier/Epoch{:d}.pth.tar'.format((i + 1), min_valid_loss))\n",
    "    \n",
    "\n",
    "    # Log\n",
    "    log_string = ('iter: [{:d}/{:d}], train_loss: {:0.6f}, valid_loss: {:0.6f}, '\n",
    "                  'best_valid_loss: {:0.6f}, lr: {:0.7f}').format((i + 1), EPOCH,\n",
    "                                                                  train_loss[-1],\n",
    "                                                                  valid_loss[-1],\n",
    "                                                                  min_valid_loss,\n",
    "                                                                  optimizer.param_groups[0]['lr'])\n",
    "    mult_step_scheduler.step()  # 学习率更新\n",
    "    print(log_string)  # 打印日志\n",
    "    \n",
    "bpali_file.close()\n",
    "fbank_scp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0013b9c",
   "metadata": {},
   "source": [
    "Read bpali data & fbank data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f64d942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 652, 40)\n",
      "(1, 693, 40)\n",
      "(1, 1069, 40)\n"
     ]
    }
   ],
   "source": [
    "import kaldiark\n",
    "bpali_file = open('./data/train-si284.bpali', 'rb')\n",
    "fbank_scp = open('./data/si284-0.9-train.fbank.scp', 'rb')\n",
    "fbank_lines = fbank_scp.readlines()\n",
    "with open('./data/si284-0.9-train.bpali.scp', 'rb') as scp_file:\n",
    "    bpali_lines = scp_file.readlines()\n",
    "    for i,line in enumerate(bpali_lines[:3]):\n",
    "        # Find the label\n",
    "        temp = str(line).split()[1]\n",
    "        pointer = temp.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the label\n",
    "        # Linux only has \\n\n",
    "        bpali_file.seek(int(pointer))\n",
    "        transcript = bpali_file.readline()\n",
    "        # print(str(transcript)[2:-3])\n",
    "#         # Windows contain \\r\\n instead of \\n\n",
    "#         bpali_file.seek(int(pointer)-1)\n",
    "#         transcript = str(bpali_file.readlines()[1])[2:-3].replace('\\\\r', '')\n",
    "#         out_list = transcript.split()\n",
    "#         print(out_list)\n",
    "\n",
    "        # Find the utterance\n",
    "        utt_line = fbank_lines[i]\n",
    "        temp = str(utt_line).split()[1]\n",
    "        utt_file_loc = temp.split(':')[0][24:]  # ark file path; keep [14:]\n",
    "        utt_pointer = temp.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the utterance\n",
    "        # print(file_loc, pointer)\n",
    "        # According to the file name and pointer to get the matrix\n",
    "        with open('./data' + utt_file_loc, 'rb') as ark_file:\n",
    "            ark_file.seek(int(utt_pointer))\n",
    "            utt_mat = kaldiark.parse_feat_matrix(ark_file)         \n",
    "            utt_mat = np.expand_dims(utt_mat, axis=0)  # expand a new dimension as batch\n",
    "            print(utt_mat.shape)\n",
    "\n",
    "bpali_file.close()\n",
    "fbank_scp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9ee2f3",
   "metadata": {},
   "source": [
    "Run the linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9facfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# para prep\n",
    "HIDDEN_SIZE = 40  # WILL BE USE 512\n",
    "OUTPUT_SIZE = 43\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCH = 20\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # \n",
    "\n",
    "# classifier use representation dimension as input size -- i.e. HIDDEN_SIZE\n",
    "classifier = classification_net(input_size=HIDDEN_SIZE, hidden_size=HIDDEN_SIZE, output_size=OUTPUT_SIZE).to(DEVICE)  \n",
    "# print(net)  \n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=LEARNING_RATE)  # optimize all parameters\n",
    "# Learning rate decay schedule\n",
    "mult_step_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                                           milestones=[EPOCH // 2, EPOCH // 4 * 3], gamma=0.1)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# Train + Dev\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "min_valid_loss = np.inf\n",
    "for i in range(EPOCH):\n",
    "    total_train_loss = []\n",
    "    rnn.train()  # Training\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    for idx, (images,labels) in enumerate(train_dataloader):\n",
    "        x =images.reshape(-1,28*28)\n",
    "\n",
    "        x=x.to(DEVICE)# 如果用CPU去掉\n",
    "        labels=labels.to(DEVICE)# 如果用CPU去掉\n",
    "\n",
    "        optimizer.zero_grad() #梯度清零\n",
    "        preds=fc(x) #计算预测\n",
    "        loss=loss_func(preds,labels) #计算损失\n",
    "        loss.backward() # 计算参数梯度\n",
    "        optimizer.step() # 更新迭代梯度\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Use the total scp files\n",
    "    # Read data index from the total scp file\n",
    "    with open('./data/raw_fbank_train_si284.1.scp', 'rb') as scp_file:\n",
    "        lines = scp_file.readlines()\n",
    "        for line in lines[:2]:  # use 2 utt to test\n",
    "            temp = str(line).split()[1]\n",
    "            file_loc = temp.split(':')[0][28:]  # ark file path; keep [18:]\n",
    "            pointer = temp.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the utterance\n",
    "#             print(file_loc, pointer)\n",
    "\n",
    "            # According to the file name and pointer to get the matrix\n",
    "            with open('./data' + file_loc, 'rb') as ark_file:\n",
    "                ark_file.seek(int(pointer))\n",
    "                utt_mat = kaldiark.parse_feat_matrix(ark_file)\n",
    "            \n",
    "                utt_mat = np.expand_dims(utt_mat, axis=0)  # expand a new dimension as batch\n",
    "                utt_mat = torch.Tensor(utt_mat).to(DEVICE)   # change data to tensor\n",
    "                output = rnn(utt_mat[:, :-K, :])\n",
    "                \n",
    "#                 print(utt_mat.shape, output.shape)\n",
    "\n",
    "                loss = loss_func(output, utt_mat[:, K:, :])  # compute the difference\n",
    "                optimizer.zero_grad()  # clear gradients for this training step\n",
    "                loss.backward()  # back-prop\n",
    "                optimizer.step()  # gradients\n",
    "                total_train_loss.append(loss.item())\n",
    "        train_loss.append(np.mean(total_train_loss))\n",
    "    # print('train complete!')\n",
    "\n",
    "    total_valid_loss = []\n",
    "    rnn.eval()  # Validation\n",
    "    \n",
    "    # Use one of scp files\n",
    "    # Read data index from the total scp file\n",
    "    with open('./data/raw_fbank_train_si284.2.scp', 'rb') as scp_file:  # change 1 to dev \n",
    "        lines = scp_file.readlines()\n",
    "        for line in lines[:3]:\n",
    "            temp = str(line).split()[1]\n",
    "            file_loc = temp.split(':')[0][28:]  # ark file path; keep [18:]\n",
    "            pointer = temp.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the utterance\n",
    "\n",
    "            # According to the file name and pointer to get the matrix\n",
    "            with open('./data' + file_loc, 'rb') as ark_file:\n",
    "                ark_file.seek(int(pointer))\n",
    "                utt_mat = kaldiark.parse_feat_matrix(ark_file)\n",
    "            \n",
    "                utt_mat = np.expand_dims(utt_mat, axis=0)  # expand a new dimension as batch\n",
    "                utt_mat = torch.Tensor(utt_mat).to(device)   # change data to tensor\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    output = rnn(utt_mat[:, :-K, :])  # rnn output\n",
    "                    \n",
    "#                     print(utt_mat_mat.shape, output.shape)\n",
    "\n",
    "                loss = loss_func(output, utt_mat[:, K:, :])\n",
    "            total_valid_loss.append(loss.item())\n",
    "        valid_loss.append(np.mean(total_valid_loss))\n",
    "    # print('dev complete!')\n",
    "    \n",
    "    # save the net\n",
    "\n",
    "    min_valid_loss = np.min(valid_loss)\n",
    "    \n",
    "    if ((i + 1) % 10 == 0):\n",
    "        torch.save({'epoch': i + 1, 'state_dict': rnn.state_dict(), 'train_loss': train_loss,\n",
    "                    'valid_loss': valid_loss, 'optimizer': optimizer.state_dict()},\n",
    "                    './model_classifier/Epoch{:d}.pth.tar'.format((i + 1), min_valid_loss))\n",
    "    \n",
    "\n",
    "    # Log\n",
    "    log_string = ('iter: [{:d}/{:d}], train_loss: {:0.6f}, valid_loss: {:0.6f}, '\n",
    "                  'best_valid_loss: {:0.6f}, lr: {:0.7f}').format((i + 1), EPOCH,\n",
    "                                                                  train_loss[-1],\n",
    "                                                                  valid_loss[-1],\n",
    "                                                                  min_valid_loss,\n",
    "                                                                  optimizer.param_groups[0]['lr'])\n",
    "    mult_step_scheduler.step()  # 学习率更新\n",
    "    print(log_string)  # 打印日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2312ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72743da1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5848b583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from functions import load_model\n",
    "from apc import toy_lstm\n",
    "import kaldiark\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PATH = './model/Epoch1.pth.tar'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "INPUT_SIZE = 40\n",
    "HIDDEN_SIZE = 512\n",
    "LAYERS = 4\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# 对照-使用默认参数\n",
    "rnn_raw = toy_lstm(INPUT_SIZE=INPUT_SIZE, HIDDEN_SIZE=HIDDEN_SIZE, LAYERS=LAYERS).to(device)\n",
    "optimizer_raw = torch.optim.Adam(rnn_raw.parameters(), lr=LEARNING_RATE)  # optimize all parameters\n",
    "\n",
    "# 使用预训练参数\n",
    "rnn_pretrain = toy_lstm(INPUT_SIZE=INPUT_SIZE, HIDDEN_SIZE=HIDDEN_SIZE, LAYERS=LAYERS).to(device)\n",
    "optimizer_pretrain = torch.optim.Adam(rnn_pretrain.parameters(), lr=LEARNING_RATE)  # optimize all parameters\n",
    "rnn_pretrain, optimizer_pretrain = load_model(PATH, rnn_pretrain, optimizer_pretrain)\n",
    "\n",
    "rnn_pretrain.eval()\n",
    "rnn_raw.eval()\n",
    "\n",
    "# get 2 utt mats:\n",
    "# Predefine the prediction gap\n",
    "K = 2  # predefine the gap\n",
    "\n",
    "ori_mat = []\n",
    "pre_mat = []\n",
    "with open('./data/raw_fbank_train_si284.1.scp', 'rb') as scp_file:\n",
    "    # mlp use: './data/raw_fbank_train_si284.1.scp'\n",
    "    # win use: './data/raw_fbank_train_si284.1.scp'\n",
    "    lines = scp_file.readlines()\n",
    "    # for line in lines[:2]:  # use 1 utt to test\n",
    "    temp = str(lines[0]).split()[1]\n",
    "    file_loc = temp.split(':')[0][28:]  # ark file path; keep [18:]\n",
    "    pointer = temp.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the utterance\n",
    "\n",
    "    # According to the file name and pointer to get the matrix\n",
    "    with open('./data' + file_loc, 'rb') as ark_file:\n",
    "        ark_file.seek(int(pointer))\n",
    "        utt_mat = kaldiark.parse_feat_matrix(ark_file)\n",
    "\n",
    "        utt_mat = np.expand_dims(utt_mat, axis=0)  # expand a new dimension as batch\n",
    "        utt_mat = torch.Tensor(utt_mat).to(device)   # change data to tensor\n",
    "\n",
    "        output_raw = rnn_raw(utt_mat[:, :-K, :])\n",
    "        output_pretrain = rnn_pretrain(utt_mat[:, :-K, :])\n",
    "\n",
    "        ori_mat.append(utt_mat[0, :-K, :])\n",
    "        pre_mat.append(output_raw[0])\n",
    "        pre_mat.append(output_pretrain[0])\n",
    "\n",
    "m1 = ori_mat[0].cpu().numpy()\n",
    "m2 = pre_mat[0].cpu().detach().numpy()\n",
    "m3 = pre_mat[1].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45c7fff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save Image Function\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = plt.gca()\n",
    "cax = plt.imshow(m1[50:100], cmap='viridis')\n",
    "plt.savefig('origin.pdf')\n",
    "\n",
    "cax = plt.imshow(m2[50:100], cmap='viridis')\n",
    "plt.savefig('raw.pdf')\n",
    "\n",
    "cax = plt.imshow(m3[50:100], cmap='viridis')\n",
    "plt.savefig('pretrained.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fbfa20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edd0282c",
   "metadata": {},
   "source": [
    "check the pre-train model's previous layer parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60ade32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): LSTM(40, 512, num_layers=4, batch_first=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from functions import load_model\n",
    "from apc import toy_lstm\n",
    "import kaldiark\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PATH = './model/Epoch1.pth.tar'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "INPUT_SIZE = 40\n",
    "HIDDEN_SIZE = 512\n",
    "LAYERS = 4\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# 使用预训练参数\n",
    "rnn_pretrain = toy_lstm(INPUT_SIZE=INPUT_SIZE, HIDDEN_SIZE=HIDDEN_SIZE, LAYERS=LAYERS).to(device)\n",
    "optimizer_pretrain = torch.optim.Adam(rnn_pretrain.parameters(), lr=LEARNING_RATE)  # optimize all parameters\n",
    "rnn_pretrain, optimizer_pretrain = load_model(PATH, rnn_pretrain, optimizer_pretrain)\n",
    "\n",
    "rnn_pretrain.eval()\n",
    "\n",
    "model2 = nn.Sequential(*list(rnn_pretrain.children())[:1])\n",
    "model2.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1d500c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
