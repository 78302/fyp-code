{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cf06a8e",
   "metadata": {},
   "source": [
    "# APC Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4070a9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "# import torchvision\n",
    "\n",
    "INPUT_SIZE = 40\n",
    "HIDDEN_SIZE = 512  # units inside the lstm\n",
    "# DROP_RATE = 0.2  # drop-out rate\n",
    "LAYERS = 1  # number of lstm layers, will be increased to 4\n",
    "\n",
    "\n",
    "class toy_lstm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(toy_lstm, self).__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=HIDDEN_SIZE,\n",
    "            num_layers=LAYERS,\n",
    "#             dropout=DROP_RATE,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(HIDDEN_SIZE, 40)  # fully connected layer\n",
    "        self.h_s = None\n",
    "        self.h_c = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        r_out, (h_s, h_c) = self.rnn(x)\n",
    "        output = self.fc(r_out)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58a25b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kaldiark\n",
    "\n",
    "# # Read data index from the total scp file\n",
    "\n",
    "# count = 0\n",
    "\n",
    "# with open('./data/raw_fbank_train_si284.1.scp', 'rb') as scp_file:  # use '../remote/data/wsj/fbank/' replace '/data/'\n",
    "#     lines = scp_file.readlines()\n",
    "#     for line in lines: # line is like b'4avc040p /home/htang2/kaldi/wsj/fbank/raw_fbank_train_si284.10.ark:2769059\\n'\n",
    "#         temp = str(line).split()[1]\n",
    "#         print(temp)\n",
    "#         file_loc = temp.split(':')[0][28:]  # ark file path; keep [18:]\n",
    "#         pointer = temp.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the utterance\n",
    "#         print(file_loc)\n",
    "#         print(pointer)\n",
    "\n",
    "#         # According to the file name and pointer to get the matrix\n",
    "#         with open('./data' + file_loc, 'rb') as ark_file:  # use '../remote/data' + file_loc replace './data/' + file_loc\n",
    "#             ark_file.seek(int(pointer))\n",
    "#             utt_mat = kaldiark.parse_feat_matrix(ark_file)\n",
    "#             print(utt_mat.shape)  \n",
    "        \n",
    "#         count = count + 1\n",
    "#         if count > 10:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6242663c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: [1/60], train_loss: 185.335281, valid_loss: 107.390554, best_valid_loss: 107.390554, lr: 0.0050000\n",
      "iter: [2/60], train_loss: 118.975380, valid_loss: 66.732348, best_valid_loss: 66.732348, lr: 0.0050000\n",
      "iter: [3/60], train_loss: 74.532879, valid_loss: 37.939902, best_valid_loss: 37.939902, lr: 0.0050000\n",
      "iter: [4/60], train_loss: 42.338984, valid_loss: 21.579492, best_valid_loss: 21.579492, lr: 0.0050000\n",
      "iter: [5/60], train_loss: 22.557779, valid_loss: 16.344495, best_valid_loss: 16.344495, lr: 0.0050000\n",
      "iter: [6/60], train_loss: 13.814932, valid_loss: 19.274874, best_valid_loss: 16.344495, lr: 0.0050000\n",
      "iter: [7/60], train_loss: 13.090472, valid_loss: 26.252875, best_valid_loss: 16.344495, lr: 0.0050000\n",
      "iter: [8/60], train_loss: 16.465832, valid_loss: 33.299493, best_valid_loss: 16.344495, lr: 0.0050000\n",
      "iter: [9/60], train_loss: 20.382216, valid_loss: 37.702118, best_valid_loss: 16.344495, lr: 0.0050000\n",
      "iter: [10/60], train_loss: 22.570373, valid_loss: 38.490917, best_valid_loss: 16.344495, lr: 0.0050000\n",
      "iter: [11/60], train_loss: 22.241153, valid_loss: 35.775551, best_valid_loss: 16.344495, lr: 0.0050000\n",
      "iter: [12/60], train_loss: 19.916075, valid_loss: 31.479891, best_valid_loss: 16.344495, lr: 0.0050000\n",
      "iter: [13/60], train_loss: 17.029061, valid_loss: 26.915883, best_valid_loss: 16.344495, lr: 0.0050000\n",
      "iter: [14/60], train_loss: 14.421190, valid_loss: 22.884276, best_valid_loss: 16.344495, lr: 0.0050000\n",
      "iter: [15/60], train_loss: 12.644375, valid_loss: 19.857562, best_valid_loss: 16.344495, lr: 0.0050000\n",
      "iter: [16/60], train_loss: 11.865329, valid_loss: 17.857606, best_valid_loss: 16.344495, lr: 0.0050000\n",
      "iter: [17/60], train_loss: 11.926786, valid_loss: 16.824047, best_valid_loss: 16.344495, lr: 0.0050000\n",
      "iter: [18/60], train_loss: 12.327363, valid_loss: 16.303992, best_valid_loss: 16.303992, lr: 0.0050000\n",
      "iter: [19/60], train_loss: 12.682915, valid_loss: 16.042475, best_valid_loss: 16.042475, lr: 0.0050000\n",
      "iter: [20/60], train_loss: 12.778398, valid_loss: 15.939068, best_valid_loss: 15.939068, lr: 0.0050000\n",
      "iter: [21/60], train_loss: 12.592671, valid_loss: 16.005062, best_valid_loss: 15.939068, lr: 0.0050000\n",
      "iter: [22/60], train_loss: 12.240403, valid_loss: 16.286565, best_valid_loss: 15.939068, lr: 0.0050000\n",
      "iter: [23/60], train_loss: 11.877368, valid_loss: 16.791387, best_valid_loss: 15.939068, lr: 0.0050000\n",
      "iter: [24/60], train_loss: 11.618578, valid_loss: 17.454460, best_valid_loss: 15.939068, lr: 0.0050000\n",
      "iter: [25/60], train_loss: 11.500014, valid_loss: 18.150913, best_valid_loss: 15.939068, lr: 0.0050000\n",
      "iter: [26/60], train_loss: 11.487948, valid_loss: 18.741211, best_valid_loss: 15.939068, lr: 0.0050000\n",
      "iter: [27/60], train_loss: 11.517526, valid_loss: 19.120375, best_valid_loss: 15.939068, lr: 0.0050000\n",
      "iter: [28/60], train_loss: 11.533529, valid_loss: 19.247209, best_valid_loss: 15.939068, lr: 0.0050000\n",
      "iter: [29/60], train_loss: 11.512887, valid_loss: 19.144683, best_valid_loss: 15.939068, lr: 0.0050000\n",
      "iter: [30/60], train_loss: 11.463619, valid_loss: 18.878307, best_valid_loss: 15.939068, lr: 0.0050000\n",
      "iter: [31/60], train_loss: 11.426764, valid_loss: 18.840885, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [32/60], train_loss: 11.419742, valid_loss: 18.794208, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [33/60], train_loss: 11.411001, valid_loss: 18.740578, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [34/60], train_loss: 11.401130, valid_loss: 18.682035, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [35/60], train_loss: 11.390662, valid_loss: 18.620356, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [36/60], train_loss: 11.380048, valid_loss: 18.557067, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [37/60], train_loss: 11.369654, valid_loss: 18.493443, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [38/60], train_loss: 11.359757, valid_loss: 18.430542, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [39/60], train_loss: 11.350563, valid_loss: 18.369211, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [40/60], train_loss: 11.342200, valid_loss: 18.310118, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [41/60], train_loss: 11.334740, valid_loss: 18.253774, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [42/60], train_loss: 11.328201, valid_loss: 18.200551, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [43/60], train_loss: 11.322568, valid_loss: 18.150693, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [44/60], train_loss: 11.317795, valid_loss: 18.104359, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [45/60], train_loss: 11.313814, valid_loss: 18.061617, best_valid_loss: 15.939068, lr: 0.0005000\n",
      "iter: [46/60], train_loss: 11.311796, valid_loss: 18.057674, best_valid_loss: 15.939068, lr: 0.0000500\n",
      "iter: [47/60], train_loss: 11.311505, valid_loss: 18.054000, best_valid_loss: 15.939068, lr: 0.0000500\n",
      "iter: [48/60], train_loss: 11.311231, valid_loss: 18.050543, best_valid_loss: 15.939068, lr: 0.0000500\n",
      "iter: [49/60], train_loss: 11.310972, valid_loss: 18.047269, best_valid_loss: 15.939068, lr: 0.0000500\n",
      "iter: [50/60], train_loss: 11.310726, valid_loss: 18.044142, best_valid_loss: 15.939068, lr: 0.0000500\n",
      "iter: [51/60], train_loss: 11.310491, valid_loss: 18.041143, best_valid_loss: 15.939068, lr: 0.0000500\n",
      "iter: [52/60], train_loss: 11.310265, valid_loss: 18.038245, best_valid_loss: 15.939068, lr: 0.0000500\n",
      "iter: [53/60], train_loss: 11.310047, valid_loss: 18.035432, best_valid_loss: 15.939068, lr: 0.0000500\n",
      "iter: [54/60], train_loss: 11.309836, valid_loss: 18.032693, best_valid_loss: 15.939068, lr: 0.0000500\n",
      "iter: [55/60], train_loss: 11.309631, valid_loss: 18.030011, best_valid_loss: 15.939068, lr: 0.0000500\n",
      "iter: [56/60], train_loss: 11.309430, valid_loss: 18.027380, best_valid_loss: 15.939068, lr: 0.0000500\n",
      "iter: [57/60], train_loss: 11.309235, valid_loss: 18.024790, best_valid_loss: 15.939068, lr: 0.0000500\n",
      "iter: [58/60], train_loss: 11.309043, valid_loss: 18.022238, best_valid_loss: 15.939068, lr: 0.0000500\n",
      "iter: [59/60], train_loss: 11.308856, valid_loss: 18.019716, best_valid_loss: 15.939068, lr: 0.0000500\n",
      "iter: [60/60], train_loss: 11.308671, valid_loss: 18.017221, best_valid_loss: 15.939068, lr: 0.0000500\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import kaldiark\n",
    "from apc import toy_lstm\n",
    "import glob\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # \n",
    "\n",
    "LEARNING_RATE = 0.005\n",
    "EPOCH = 60\n",
    "\n",
    "rnn = toy_lstm().to(device)  \n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LEARNING_RATE)  # optimize all parameters\n",
    "loss_func = nn.MSELoss()\n",
    "# Learning rate decay schedule\n",
    "mult_step_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                                           milestones=[EPOCH // 2, EPOCH // 4 * 3], gamma=0.1)\n",
    "\n",
    "# Predefine the prediction gap\n",
    "K = 2  # predefine the gap\n",
    "\n",
    "# Train + Dev\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "min_valid_loss = np.inf\n",
    "for i in range(EPOCH):\n",
    "    total_train_loss = []\n",
    "    rnn.train()  # Training\n",
    "    \n",
    "    # Use the total scp files\n",
    "    # Read data index from the total scp file\n",
    "    with open('./data/raw_fbank_train_si284.1.scp', 'rb') as scp_file:\n",
    "        lines = scp_file.readlines()\n",
    "        for line in lines[:2]:  # use 2 utt to test\n",
    "            temp = str(line).split()[1]\n",
    "            file_loc = temp.split(':')[0][28:]  # ark file path; keep [18:]\n",
    "            pointer = temp.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the utterance\n",
    "#             print(file_loc, pointer)\n",
    "\n",
    "            # According to the file name and pointer to get the matrix\n",
    "            with open('./data' + file_loc, 'rb') as ark_file:\n",
    "                ark_file.seek(int(pointer))\n",
    "                utt_mat = kaldiark.parse_feat_matrix(ark_file)\n",
    "            \n",
    "                utt_mat = np.expand_dims(utt_mat, axis=0)  # expand a new dimension as batch\n",
    "                utt_mat = torch.Tensor(utt_mat).to(device)   # change data to tensor\n",
    "                output = rnn(utt_mat[:, :-K, :])\n",
    "                \n",
    "#                 print(utt_mat.shape, output.shape)\n",
    "\n",
    "                loss = loss_func(output, utt_mat[:, K:, :])  # compute the difference\n",
    "                optimizer.zero_grad()  # clear gradients for this training step\n",
    "                loss.backward()  # back-prop\n",
    "                optimizer.step()  # gradients\n",
    "                total_train_loss.append(loss.item())\n",
    "        train_loss.append(np.mean(total_train_loss))\n",
    "    # print('train complete!')\n",
    "\n",
    "    total_valid_loss = []\n",
    "    rnn.eval()  # Validation\n",
    "    \n",
    "    # Use one of scp files\n",
    "    # Read data index from the total scp file\n",
    "    with open('./data/raw_fbank_train_si284.2.scp', 'rb') as scp_file:  # change 1 to dev \n",
    "        lines = scp_file.readlines()\n",
    "        for line in lines[:3]:\n",
    "            temp = str(line).split()[1]\n",
    "            file_loc = temp.split(':')[0][28:]  # ark file path; keep [18:]\n",
    "            pointer = temp.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the utterance\n",
    "\n",
    "            # According to the file name and pointer to get the matrix\n",
    "            with open('./data' + file_loc, 'rb') as ark_file:\n",
    "                ark_file.seek(int(pointer))\n",
    "                utt_mat = kaldiark.parse_feat_matrix(ark_file)\n",
    "            \n",
    "                utt_mat = np.expand_dims(utt_mat, axis=0)  # expand a new dimension as batch\n",
    "                utt_mat = torch.Tensor(utt_mat).to(device)   # change data to tensor\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    output = rnn(utt_mat[:, :-K, :])  # rnn output\n",
    "                    \n",
    "#                     print(utt_mat_mat.shape, output.shape)\n",
    "\n",
    "                loss = loss_func(output, utt_mat[:, K:, :])\n",
    "            total_valid_loss.append(loss.item())\n",
    "        valid_loss.append(np.mean(total_valid_loss))\n",
    "    # print('dev complete!')\n",
    "    \n",
    "    # save the net\n",
    "\n",
    "    min_valid_loss = np.min(valid_loss)\n",
    "    \n",
    "    if ((i + 1) % 10 == 0):\n",
    "        torch.save({'epoch': i + 1, 'state_dict': rnn.state_dict(), 'train_loss': train_loss,\n",
    "                    'valid_loss': valid_loss, 'optimizer': optimizer.state_dict()},\n",
    "                    './model/Epoch{:d}.pth.tar'.format((i + 1), min_valid_loss))\n",
    "    \n",
    "\n",
    "    # Log\n",
    "    log_string = ('iter: [{:d}/{:d}], train_loss: {:0.6f}, valid_loss: {:0.6f}, '\n",
    "                  'best_valid_loss: {:0.6f}, lr: {:0.7f}').format((i + 1), EPOCH,\n",
    "                                                                  train_loss[-1],\n",
    "                                                                  valid_loss[-1],\n",
    "                                                                  min_valid_loss,\n",
    "                                                                  optimizer.param_groups[0]['lr'])\n",
    "    mult_step_scheduler.step()  # 学习率更新\n",
    "    print(log_string)  # 打印日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e8eeb9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt  \n",
    "matplotlib.use('Agg')\n",
    "y = train_loss\n",
    "x = np.arange(0,len(train_loss))\n",
    "fig, ax = plt.subplots(figsize=(14,7))\n",
    "ax.plot(x,y,'r--',label='type1')\n",
    "\n",
    "ax.set_title('Loss',fontsize=18)\n",
    "ax.set_xlabel('epoch', fontsize=18,fontfamily = 'sans-serif',fontstyle='italic')\n",
    "ax.set_ylabel('loss', fontsize='x-large',fontstyle='oblique')\n",
    "ax.legend()\n",
    "\n",
    "plt.savefig(\"loss.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "adb3d3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path, model, optimizer):\n",
    "    \n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    return model, optimizer\n",
    "\n",
    "PATH = './model/Epoch60.pth.tar'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 对照-使用默认参数\n",
    "rnn_raw = toy_lstm().to(device)\n",
    "optimizer_raw = torch.optim.Adam(rnn.parameters(), lr=LEARNING_RATE)  # optimize all parameters\n",
    "\n",
    "# 使用预训练参数\n",
    "rnn_pretrain = toy_lstm().to(device)\n",
    "optimizer_pretrain = torch.optim.Adam(rnn.parameters(), lr=LEARNING_RATE)  # optimize all parameters\n",
    "rnn_pretrain, optimizer_pretrain = load_model(PATH, rnn_pretrain, optimizer_pretrain)\n",
    "\n",
    "rnn_pretrain.eval()\n",
    "rnn_raw.eval()\n",
    "\n",
    "# get 2 utt mats:\n",
    "# Predefine the prediction gap\n",
    "K = 2  # predefine the gap\n",
    "\n",
    "ori_mat = []\n",
    "pre_mat = []\n",
    "with open('./data/raw_fbank_train_si284.1.scp', 'rb') as scp_file:\n",
    "    lines = scp_file.readlines()\n",
    "    # for line in lines[:2]:  # use 1 utt to test\n",
    "    temp = str(lines[0]).split()[1]\n",
    "    file_loc = temp.split(':')[0][28:]  # ark file path; keep [18:]\n",
    "    pointer = temp.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the utterance\n",
    "\n",
    "    # According to the file name and pointer to get the matrix\n",
    "    with open('./data' + file_loc, 'rb') as ark_file:\n",
    "        ark_file.seek(int(pointer))\n",
    "        utt_mat = kaldiark.parse_feat_matrix(ark_file)\n",
    "            \n",
    "        utt_mat = np.expand_dims(utt_mat, axis=0)  # expand a new dimension as batch\n",
    "        utt_mat = torch.Tensor(utt_mat).to(device)   # change data to tensor\n",
    "        \n",
    "        output_raw = rnn_raw(utt_mat[:, :-K, :])\n",
    "        output_pretrain = rnn_pretrain(utt_mat[:, :-K, :])\n",
    "                \n",
    "        ori_mat.append(utt_mat[0, :-K, :])\n",
    "        pre_mat.append(output_raw[0])\n",
    "        pre_mat.append(output_pretrain[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fcfd1d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = ori_mat[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "11eb4c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = pre_mat[0].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f03e69c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = pre_mat[1].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "503f6f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Save Image Function\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = plt.gca()\n",
    "cax = plt.imshow(m1, cmap='viridis')\n",
    "# # set up colorbar\n",
    "# cbar = plt.colorbar(cax, extend='both', drawedges = False)\n",
    "# cbar.set_label('Intensity',size=36, weight =  'bold')\n",
    "# cbar.ax.tick_params( labelsize=18 )\n",
    "# cbar.minorticks_on()\n",
    "# # set up axis labels\n",
    "# ticks=np.arange(0,m1.shape[0],1)\n",
    "# ## For x ticks\n",
    "# plt.xticks(ticks, fontsize=12, fontweight = 'bold')\n",
    "# ax.set_xticklabels(ticks)\n",
    "# ## For y ticks\n",
    "# plt.yticks(ticks, fontsize=12, fontweight = 'bold')\n",
    "# ax.set_yticklabels(ticks)\n",
    "plt.savefig('origin.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "301b5680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Image Function\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = plt.gca()\n",
    "cax = plt.imshow(m2, cmap='viridis')\n",
    "plt.savefig('raw.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4f60ac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Image Function\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = plt.gca()\n",
    "cax = plt.imshow(m3, cmap='viridis')\n",
    "plt.savefig('pretrained.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2d8f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f8add9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae262ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84151745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.9013,  3.5482,  3.9370,  ..., 12.6050, 12.6487, 12.5332],\n",
      "        [ 3.8091,  3.2036,  3.6625,  ..., 12.8245, 12.6994, 12.1048],\n",
      "        [ 4.3622,  3.4333,  4.2115,  ..., 12.7971, 12.9021, 12.0844],\n",
      "        ...,\n",
      "        [ 4.1779,  3.2036,  3.3879,  ..., 12.6324, 12.7501, 11.7375],\n",
      "        [ 3.8091,  2.1698,  3.7997,  ..., 12.7971, 12.3445, 11.7579],\n",
      "        [ 3.3482,  3.0887,  3.3879,  ..., 13.0715, 13.1809, 12.4312]])\n",
      "tensor([[ 3.9013,  3.5482,  3.9370,  ..., 12.6050, 12.6487, 12.5332],\n",
      "        [ 3.8091,  3.2036,  3.6625,  ..., 12.8245, 12.6994, 12.1048],\n",
      "        [ 4.3622,  3.4333,  4.2115,  ..., 12.7971, 12.9021, 12.0844],\n",
      "        ...,\n",
      "        [ 3.9013,  4.3522,  3.1134,  ..., 12.8245, 12.6233, 12.3904],\n",
      "        [ 3.7170,  4.6968,  4.6233,  ..., 12.9343, 12.9528, 12.4108],\n",
      "        [ 4.1779,  3.2036,  3.3879,  ..., 12.6324, 12.7501, 11.7375]])\n",
      "tensor([[-0.0204, -0.0401,  0.1698,  ...,  0.0237, -0.0143,  0.0480],\n",
      "        [ 0.0033, -0.0277,  0.1911,  ...,  0.0355, -0.0017,  0.0486],\n",
      "        [ 0.0229,  0.0054,  0.2038,  ...,  0.0396,  0.0291,  0.0517],\n",
      "        ...,\n",
      "        [ 0.0650,  0.0404,  0.2205,  ...,  0.0443,  0.1243,  0.0175],\n",
      "        [ 0.0562,  0.0354,  0.2289,  ...,  0.0473,  0.1081,  0.0246],\n",
      "        [ 0.0705,  0.0546,  0.2297,  ...,  0.0468,  0.1078,  0.0308]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([[ 7.1982,  7.3003,  7.7380,  ...,  8.3063,  8.5552,  8.2469],\n",
      "        [ 9.6438,  9.7859, 10.4431,  ..., 11.1874, 11.5854, 11.1365],\n",
      "        [10.0378, 10.1777, 10.8667,  ..., 11.6556, 12.0799, 11.6058],\n",
      "        ...,\n",
      "        [10.1030, 10.2439, 10.9385,  ..., 11.7354, 12.1617, 11.6827],\n",
      "        [10.1031, 10.2435, 10.9391,  ..., 11.7349, 12.1623, 11.6826],\n",
      "        [10.1047, 10.2435, 10.9370,  ..., 11.7358, 12.1616, 11.6829]],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(utt_mat[0])\n",
    "print(ori_mat[0])\n",
    "print(pre_mat[0])\n",
    "print(pre_mat[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eb6847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "147517be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['rnn.weight_ih_l0', 'rnn.weight_hh_l0', 'rnn.bias_ih_l0', 'rnn.bias_hh_l0', 'fc.weight', 'fc.bias'])\n",
      "<class 'collections.OrderedDict'>\n"
     ]
    }
   ],
   "source": [
    "load_dict = torch.load('./model/Epoch30.pth.tar')['state_dict']\n",
    "print(load_dict.keys())\n",
    "print(type(load_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6502385c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4b3339c",
   "metadata": {},
   "source": [
    "# Probing Task Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79a96264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "class classification_net(torch.nn.Module):  \n",
    "    def __init__(self, input_size, hidden_size, output_size):  \n",
    "        super(classification_net, self).__init__()  \n",
    "        self.hidden_layer = torch.nn.Linear(input_size, hidden_size)  \n",
    "        self.out = torch.nn.Linear(hidden_size, output_size)  \n",
    "    def forward(self, x):  \n",
    "        x = torch.relu(self.hidden_layer(x))  \n",
    "        x = self.out(x) \n",
    "        x = torch.nn.functional.softmax(x)  \n",
    "        return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fca39923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_net(\n",
      "  (hidden_layer): Linear(in_features=40, out_features=512, bias=True)\n",
      "  (out): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = classification_net(input_size=40, hidden_size=512, output_size=2)  \n",
    "print(net)  \n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.02)  \n",
    "loss_func = torch.nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a96e11c",
   "metadata": {},
   "source": [
    "One hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d8ee72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unk', 'aa', 'ae', 'ah', 'ao', 'aw', 'ay', 'b', 'ch', 'd', 'dh', 'eh', 'er', 'ey', 'f', 'g', 'hh', 'ih', 'iy', 'jh', 'k', 'l', 'm', 'n', 'ng', 'nsn', 'ow', 'oy', 'p', 'r', 's', 'sh', 'sil', 'spn', 't', 'th', 'uh', 'uw', 'v', 'w', 'y', 'z', 'zh']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open('./data/phones-unk.txt', 'r') as ph_file:\n",
    "    standard = ph_file.read().splitlines()\n",
    "    print(standard)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3c22e163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhou/anaconda3/envs/fyp/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: [1/20], train_loss: 3.763740, valid_loss: 3.774309, best_valid_loss: 3.774309, lr: 0.0010000\n",
      "iter: [2/20], train_loss: 3.781741, valid_loss: 3.774309, best_valid_loss: 3.774309, lr: 0.0010000\n",
      "iter: [3/20], train_loss: 3.754421, valid_loss: 3.716027, best_valid_loss: 3.716027, lr: 0.0010000\n",
      "iter: [4/20], train_loss: 3.724160, valid_loss: 3.716027, best_valid_loss: 3.716027, lr: 0.0010000\n",
      "iter: [5/20], train_loss: 3.724160, valid_loss: 3.716027, best_valid_loss: 3.716027, lr: 0.0010000\n",
      "iter: [6/20], train_loss: 3.724160, valid_loss: 3.716027, best_valid_loss: 3.716027, lr: 0.0010000\n",
      "iter: [7/20], train_loss: 3.724160, valid_loss: 3.716027, best_valid_loss: 3.716027, lr: 0.0010000\n",
      "iter: [8/20], train_loss: 3.724160, valid_loss: 3.716027, best_valid_loss: 3.716027, lr: 0.0010000\n",
      "iter: [9/20], train_loss: 3.724160, valid_loss: 3.716027, best_valid_loss: 3.716027, lr: 0.0010000\n",
      "iter: [10/20], train_loss: 3.737266, valid_loss: 3.778910, best_valid_loss: 3.716027, lr: 0.0010000\n",
      "iter: [11/20], train_loss: 3.771385, valid_loss: 3.778910, best_valid_loss: 3.716027, lr: 0.0001000\n",
      "iter: [12/20], train_loss: 3.771385, valid_loss: 3.778910, best_valid_loss: 3.716027, lr: 0.0001000\n",
      "iter: [13/20], train_loss: 3.771385, valid_loss: 3.778910, best_valid_loss: 3.716027, lr: 0.0001000\n",
      "iter: [14/20], train_loss: 3.771385, valid_loss: 3.778910, best_valid_loss: 3.716027, lr: 0.0001000\n",
      "iter: [15/20], train_loss: 3.771385, valid_loss: 3.778910, best_valid_loss: 3.716027, lr: 0.0001000\n",
      "iter: [16/20], train_loss: 3.771385, valid_loss: 3.778910, best_valid_loss: 3.716027, lr: 0.0000100\n",
      "iter: [17/20], train_loss: 3.771385, valid_loss: 3.778910, best_valid_loss: 3.716027, lr: 0.0000100\n",
      "iter: [18/20], train_loss: 3.771385, valid_loss: 3.778910, best_valid_loss: 3.716027, lr: 0.0000100\n",
      "iter: [19/20], train_loss: 3.771385, valid_loss: 3.778910, best_valid_loss: 3.716027, lr: 0.0000100\n",
      "iter: [20/20], train_loss: 3.771385, valid_loss: 3.778910, best_valid_loss: 3.716027, lr: 0.0000100\n"
     ]
    }
   ],
   "source": [
    "# para prep\n",
    "HIDDEN_SIZE = 40  # WILL BE USE 512\n",
    "OUTPUT_SIZE = 43\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCH = 20\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # \n",
    "\n",
    "# classifier use representation dimension as input size -- i.e. HIDDEN_SIZE\n",
    "classifier = classification_net(input_size=HIDDEN_SIZE, hidden_size=HIDDEN_SIZE, output_size=OUTPUT_SIZE).to(DEVICE)  \n",
    "# print(net)  \n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=LEARNING_RATE)  # optimize all parameters\n",
    "# Learning rate decay schedule\n",
    "mult_step_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                                           milestones=[EPOCH // 2, EPOCH // 4 * 3], gamma=0.1)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "import kaldiark\n",
    "bpali_file = open('./data/train-si284.bpali', 'rb')\n",
    "fbank_scp = open('./data/si284-0.9-train.fbank.scp', 'rb')\n",
    "fbank_lines = fbank_scp.readlines()\n",
    "\n",
    "\n",
    "# Train + Dev\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "min_valid_loss = np.inf\n",
    "for i in range(EPOCH):\n",
    "    total_train_loss = []\n",
    "    classifier.train()  # Training\n",
    "    \n",
    "    with open('./data/si284-0.9-train.bpali.scp', 'rb') as scp_file:\n",
    "        bpali_lines = scp_file.readlines()\n",
    "        for idx,line in enumerate(bpali_lines[:3]):\n",
    "            # Find the label\n",
    "            temp = str(line).split()[1]\n",
    "            pointer = temp.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the label\n",
    "            # Linux only has \\n\n",
    "            bpali_file.seek(int(pointer))\n",
    "            transcript = bpali_file.readline()\n",
    "            labels = str(transcript)[2:-3].split()\n",
    "#             print(str(transcript)[2:-3])\n",
    "\n",
    "            # Find the utterance\n",
    "            utt_line = fbank_lines[idx]\n",
    "            temp = str(utt_line).split()[1]\n",
    "            utt_file_loc = temp.split(':')[0][24:]  # ark file path; keep [14:]\n",
    "            utt_pointer = temp.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the utterance\n",
    "            # print(file_loc, pointer)\n",
    "            # According to the file name and pointer to get the matrix\n",
    "            with open('./data' + utt_file_loc, 'rb') as ark_file:\n",
    "                ark_file.seek(int(utt_pointer))\n",
    "                utt_mat = kaldiark.parse_feat_matrix(ark_file)\n",
    "                utt_mat = torch.Tensor(utt_mat).to(DEVICE)   # change data to tensor\n",
    "#                 utt_mat = np.expand_dims(utt_mat, axis=0)  # expand a new dimension as batch\n",
    "#             print(utt_mat.shape)\n",
    "\n",
    "                for idx,mat in enumerate(utt_mat):\n",
    "                    mat = torch.unsqueeze(mat, 0)\n",
    "                    x = mat.to(DEVICE)\n",
    "                    y = standard.index(labels[idx])\n",
    "                    y = torch.tensor([y], dtype=torch.long).to(DEVICE)\n",
    "                \n",
    "                    optimizer.zero_grad()\n",
    "                    output=classifier(x)\n",
    "                    loss=loss_func(output,y) \n",
    "                    \n",
    "                    loss.backward() \n",
    "                    optimizer.step() \n",
    "                    total_train_loss.append(loss.item())\n",
    "        train_loss.append(np.mean(total_train_loss))\n",
    "\n",
    "    total_valid_loss = []\n",
    "    classifier.eval()  # Validation\n",
    "    \n",
    "    with open('./data/si284-0.9-train.bpali.scp', 'rb') as scp_file:\n",
    "        bpali_lines = scp_file.readlines()\n",
    "        for idx,line in enumerate(bpali_lines[:1]):\n",
    "            # Find the label\n",
    "            temp = str(line).split()[1]\n",
    "            pointer = temp.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the label\n",
    "            # Linux only has \\n\n",
    "            bpali_file.seek(int(pointer))\n",
    "            transcript = bpali_file.readline()\n",
    "            labels = str(transcript)[2:-3].split()\n",
    "#             print(str(transcript)[2:-3])\n",
    "\n",
    "            # Find the utterance\n",
    "            utt_line = fbank_lines[idx]\n",
    "            temp = str(utt_line).split()[1]\n",
    "            utt_file_loc = temp.split(':')[0][24:]  # ark file path; keep [14:]\n",
    "            utt_pointer = temp.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the utterance\n",
    "            # print(file_loc, pointer)\n",
    "            # According to the file name and pointer to get the matrix\n",
    "            with open('./data' + utt_file_loc, 'rb') as ark_file:\n",
    "                ark_file.seek(int(utt_pointer))\n",
    "                utt_mat = kaldiark.parse_feat_matrix(ark_file)  \n",
    "                utt_mat = torch.Tensor(utt_mat).to(DEVICE)   # change data to tensor\n",
    "#                 utt_mat = np.expand_dims(utt_mat, axis=0)  # expand a new dimension as batch\n",
    "#             print(utt_mat.shape)\n",
    "\n",
    "                for idx,mat in enumerate(utt_mat):\n",
    "                    mat = torch.unsqueeze(mat, 0)\n",
    "                    x = mat.to(DEVICE)\n",
    "                    y = standard.index(labels[idx])\n",
    "                    y = torch.tensor([y], dtype=torch.long).to(DEVICE)\n",
    "                \n",
    "                    with torch.no_grad():\n",
    "                        output = classifier(x)\n",
    "                    loss=loss_func(output,y) \n",
    "                    total_valid_loss.append(loss.item())\n",
    "        valid_loss.append(np.mean(total_valid_loss))   \n",
    "    \n",
    "    # save the net\n",
    "\n",
    "    min_valid_loss = np.min(valid_loss)\n",
    "    \n",
    "    if ((i + 1) % 1 == 0):\n",
    "        torch.save({'epoch': i + 1, 'state_dict': classifier.state_dict(), 'train_loss': train_loss,\n",
    "                    'valid_loss': valid_loss, 'optimizer': optimizer.state_dict()},\n",
    "                    './model_classifier/Epoch{:d}.pth.tar'.format((i + 1), min_valid_loss))\n",
    "    \n",
    "\n",
    "    # Log\n",
    "    log_string = ('iter: [{:d}/{:d}], train_loss: {:0.6f}, valid_loss: {:0.6f}, '\n",
    "                  'best_valid_loss: {:0.6f}, lr: {:0.7f}').format((i + 1), EPOCH,\n",
    "                                                                  train_loss[-1],\n",
    "                                                                  valid_loss[-1],\n",
    "                                                                  min_valid_loss,\n",
    "                                                                  optimizer.param_groups[0]['lr'])\n",
    "    mult_step_scheduler.step()  # 学习率更新\n",
    "    print(log_string)  # 打印日志\n",
    "    \n",
    "bpali_file.close()\n",
    "fbank_scp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0013b9c",
   "metadata": {},
   "source": [
    "Read bpali data & fbank data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f64d942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 652, 40)\n",
      "(1, 693, 40)\n",
      "(1, 1069, 40)\n"
     ]
    }
   ],
   "source": [
    "import kaldiark\n",
    "bpali_file = open('./data/train-si284.bpali', 'rb')\n",
    "fbank_scp = open('./data/si284-0.9-train.fbank.scp', 'rb')\n",
    "fbank_lines = fbank_scp.readlines()\n",
    "with open('./data/si284-0.9-train.bpali.scp', 'rb') as scp_file:\n",
    "    bpali_lines = scp_file.readlines()\n",
    "    for i,line in enumerate(bpali_lines[:3]):\n",
    "        # Find the label\n",
    "        temp = str(line).split()[1]\n",
    "        pointer = temp.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the label\n",
    "        # Linux only has \\n\n",
    "        bpali_file.seek(int(pointer))\n",
    "        transcript = bpali_file.readline()\n",
    "        # print(str(transcript)[2:-3])\n",
    "#         # Windows contain \\r\\n instead of \\n\n",
    "#         bpali_file.seek(int(pointer)-1)\n",
    "#         transcript = str(bpali_file.readlines()[1])[2:-3].replace('\\\\r', '')\n",
    "#         out_list = transcript.split()\n",
    "#         print(out_list)\n",
    "\n",
    "        # Find the utterance\n",
    "        utt_line = fbank_lines[i]\n",
    "        temp = str(utt_line).split()[1]\n",
    "        utt_file_loc = temp.split(':')[0][24:]  # ark file path; keep [14:]\n",
    "        utt_pointer = temp.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the utterance\n",
    "        # print(file_loc, pointer)\n",
    "        # According to the file name and pointer to get the matrix\n",
    "        with open('./data' + utt_file_loc, 'rb') as ark_file:\n",
    "            ark_file.seek(int(utt_pointer))\n",
    "            utt_mat = kaldiark.parse_feat_matrix(ark_file)         \n",
    "            utt_mat = np.expand_dims(utt_mat, axis=0)  # expand a new dimension as batch\n",
    "            print(utt_mat.shape)\n",
    "\n",
    "bpali_file.close()\n",
    "fbank_scp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9ee2f3",
   "metadata": {},
   "source": [
    "Run the linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9facfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# para prep\n",
    "HIDDEN_SIZE = 40  # WILL BE USE 512\n",
    "OUTPUT_SIZE = 43\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCH = 20\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # \n",
    "\n",
    "# classifier use representation dimension as input size -- i.e. HIDDEN_SIZE\n",
    "classifier = classification_net(input_size=HIDDEN_SIZE, hidden_size=HIDDEN_SIZE, output_size=OUTPUT_SIZE).to(DEVICE)  \n",
    "# print(net)  \n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=LEARNING_RATE)  # optimize all parameters\n",
    "# Learning rate decay schedule\n",
    "mult_step_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                                           milestones=[EPOCH // 2, EPOCH // 4 * 3], gamma=0.1)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# Train + Dev\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "min_valid_loss = np.inf\n",
    "for i in range(EPOCH):\n",
    "    total_train_loss = []\n",
    "    rnn.train()  # Training\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    for idx, (images,labels) in enumerate(train_dataloader):\n",
    "        x =images.reshape(-1,28*28)\n",
    "\n",
    "        x=x.to(DEVICE)# 如果用CPU去掉\n",
    "        labels=labels.to(DEVICE)# 如果用CPU去掉\n",
    "\n",
    "        optimizer.zero_grad() #梯度清零\n",
    "        preds=fc(x) #计算预测\n",
    "        loss=loss_func(preds,labels) #计算损失\n",
    "        loss.backward() # 计算参数梯度\n",
    "        optimizer.step() # 更新迭代梯度\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Use the total scp files\n",
    "    # Read data index from the total scp file\n",
    "    with open('./data/raw_fbank_train_si284.1.scp', 'rb') as scp_file:\n",
    "        lines = scp_file.readlines()\n",
    "        for line in lines[:2]:  # use 2 utt to test\n",
    "            temp = str(line).split()[1]\n",
    "            file_loc = temp.split(':')[0][28:]  # ark file path; keep [18:]\n",
    "            pointer = temp.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the utterance\n",
    "#             print(file_loc, pointer)\n",
    "\n",
    "            # According to the file name and pointer to get the matrix\n",
    "            with open('./data' + file_loc, 'rb') as ark_file:\n",
    "                ark_file.seek(int(pointer))\n",
    "                utt_mat = kaldiark.parse_feat_matrix(ark_file)\n",
    "            \n",
    "                utt_mat = np.expand_dims(utt_mat, axis=0)  # expand a new dimension as batch\n",
    "                utt_mat = torch.Tensor(utt_mat).to(DEVICE)   # change data to tensor\n",
    "                output = rnn(utt_mat[:, :-K, :])\n",
    "                \n",
    "#                 print(utt_mat.shape, output.shape)\n",
    "\n",
    "                loss = loss_func(output, utt_mat[:, K:, :])  # compute the difference\n",
    "                optimizer.zero_grad()  # clear gradients for this training step\n",
    "                loss.backward()  # back-prop\n",
    "                optimizer.step()  # gradients\n",
    "                total_train_loss.append(loss.item())\n",
    "        train_loss.append(np.mean(total_train_loss))\n",
    "    # print('train complete!')\n",
    "\n",
    "    total_valid_loss = []\n",
    "    rnn.eval()  # Validation\n",
    "    \n",
    "    # Use one of scp files\n",
    "    # Read data index from the total scp file\n",
    "    with open('./data/raw_fbank_train_si284.2.scp', 'rb') as scp_file:  # change 1 to dev \n",
    "        lines = scp_file.readlines()\n",
    "        for line in lines[:3]:\n",
    "            temp = str(line).split()[1]\n",
    "            file_loc = temp.split(':')[0][28:]  # ark file path; keep [18:]\n",
    "            pointer = temp.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the utterance\n",
    "\n",
    "            # According to the file name and pointer to get the matrix\n",
    "            with open('./data' + file_loc, 'rb') as ark_file:\n",
    "                ark_file.seek(int(pointer))\n",
    "                utt_mat = kaldiark.parse_feat_matrix(ark_file)\n",
    "            \n",
    "                utt_mat = np.expand_dims(utt_mat, axis=0)  # expand a new dimension as batch\n",
    "                utt_mat = torch.Tensor(utt_mat).to(device)   # change data to tensor\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    output = rnn(utt_mat[:, :-K, :])  # rnn output\n",
    "                    \n",
    "#                     print(utt_mat_mat.shape, output.shape)\n",
    "\n",
    "                loss = loss_func(output, utt_mat[:, K:, :])\n",
    "            total_valid_loss.append(loss.item())\n",
    "        valid_loss.append(np.mean(total_valid_loss))\n",
    "    # print('dev complete!')\n",
    "    \n",
    "    # save the net\n",
    "\n",
    "    min_valid_loss = np.min(valid_loss)\n",
    "    \n",
    "    if ((i + 1) % 10 == 0):\n",
    "        torch.save({'epoch': i + 1, 'state_dict': rnn.state_dict(), 'train_loss': train_loss,\n",
    "                    'valid_loss': valid_loss, 'optimizer': optimizer.state_dict()},\n",
    "                    './model_classifier/Epoch{:d}.pth.tar'.format((i + 1), min_valid_loss))\n",
    "    \n",
    "\n",
    "    # Log\n",
    "    log_string = ('iter: [{:d}/{:d}], train_loss: {:0.6f}, valid_loss: {:0.6f}, '\n",
    "                  'best_valid_loss: {:0.6f}, lr: {:0.7f}').format((i + 1), EPOCH,\n",
    "                                                                  train_loss[-1],\n",
    "                                                                  valid_loss[-1],\n",
    "                                                                  min_valid_loss,\n",
    "                                                                  optimizer.param_groups[0]['lr'])\n",
    "    mult_step_scheduler.step()  # 学习率更新\n",
    "    print(log_string)  # 打印日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2312ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72743da1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5848b583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from functions import load_model\n",
    "from apc import toy_lstm\n",
    "import kaldiark\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PATH = './model/Epoch1.pth.tar'\n",
    "PATH = './pretrain_model/model/Epoch50.pth.tar'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "INPUT_SIZE = 40\n",
    "HIDDEN_SIZE = 512\n",
    "LAYERS = 4\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# 对照-使用默认参数\n",
    "rnn_raw = toy_lstm(INPUT_SIZE=INPUT_SIZE, HIDDEN_SIZE=HIDDEN_SIZE, LAYERS=LAYERS).to(device)\n",
    "optimizer_raw = torch.optim.Adam(rnn_raw.parameters(), lr=LEARNING_RATE)  # optimize all parameters\n",
    "\n",
    "# 使用预训练参数\n",
    "rnn_pretrain = toy_lstm(INPUT_SIZE=INPUT_SIZE, HIDDEN_SIZE=HIDDEN_SIZE, LAYERS=LAYERS).to(device)\n",
    "optimizer_pretrain = torch.optim.Adam(rnn_pretrain.parameters(), lr=LEARNING_RATE)  # optimize all parameters\n",
    "rnn_pretrain, optimizer_pretrain = load_model(PATH, rnn_pretrain, optimizer_pretrain)\n",
    "\n",
    "rnn_pretrain.eval()\n",
    "rnn_raw.eval()\n",
    "\n",
    "# get 2 utt mats:\n",
    "# Predefine the prediction gap\n",
    "K = 2  # predefine the gap\n",
    "\n",
    "ori_mat = []\n",
    "pre_mat = []\n",
    "with open('./data/raw_fbank_train_si284.1.scp', 'rb') as scp_file:\n",
    "    # mlp use: './data/raw_fbank_train_si284.1.scp'\n",
    "    # win use: './data/raw_fbank_train_si284.1.scp'\n",
    "    lines = scp_file.readlines()\n",
    "    # for line in lines[:2]:  # use 1 utt to test\n",
    "    temp = str(lines[0]).split()[1]\n",
    "    file_loc = temp.split(':')[0][28:]  # ark file path; keep [18:]\n",
    "    pointer = temp.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the utterance\n",
    "\n",
    "    # According to the file name and pointer to get the matrix\n",
    "    with open('./data' + file_loc, 'rb') as ark_file:\n",
    "        ark_file.seek(int(pointer))\n",
    "        utt_mat = kaldiark.parse_feat_matrix(ark_file)\n",
    "\n",
    "        utt_mat = np.expand_dims(utt_mat, axis=0)  # expand a new dimension as batch\n",
    "        utt_mat = torch.Tensor(utt_mat).to(device)   # change data to tensor\n",
    "\n",
    "        output_raw = rnn_raw(utt_mat[:, :-K, :])\n",
    "        output_pretrain = rnn_pretrain(utt_mat[:, :-K, :])\n",
    "\n",
    "        ori_mat.append(utt_mat[0, :-K, :])\n",
    "        pre_mat.append(output_raw[0])\n",
    "        pre_mat.append(output_pretrain[0])\n",
    "\n",
    "m1 = ori_mat[0].cpu().numpy()\n",
    "m2 = pre_mat[0].cpu().detach().numpy()\n",
    "m3 = pre_mat[1].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45c7fff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save Image Function\n",
    "fig = plt.figure(3, figsize=(10,8))\n",
    "# ax = plt.gca()\n",
    "cax = plt.imshow(m1[50:100], cmap='viridis')\n",
    "plt.savefig('origin.pdf')\n",
    "\n",
    "cax = plt.imshow(m2[50:100], cmap='viridis')\n",
    "plt.savefig('raw.pdf')\n",
    "\n",
    "cax = plt.imshow(m3[50:100], cmap='viridis')\n",
    "plt.savefig('pretrained.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fbfa20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edd0282c",
   "metadata": {},
   "source": [
    "check the pre-train model's previous layer parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60ade32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): LSTM(40, 512, num_layers=4, batch_first=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from functions import load_model\n",
    "from apc import toy_lstm\n",
    "import kaldiark\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PATH = './model/Epoch1.pth.tar'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "INPUT_SIZE = 40\n",
    "HIDDEN_SIZE = 512\n",
    "LAYERS = 4\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# 使用预训练参数\n",
    "rnn_pretrain = toy_lstm(INPUT_SIZE=INPUT_SIZE, HIDDEN_SIZE=HIDDEN_SIZE, LAYERS=LAYERS).to(device)\n",
    "optimizer_pretrain = torch.optim.Adam(rnn_pretrain.parameters(), lr=LEARNING_RATE)  # optimize all parameters\n",
    "rnn_pretrain, optimizer_pretrain = load_model(PATH, rnn_pretrain, optimizer_pretrain)\n",
    "\n",
    "rnn_pretrain.eval()\n",
    "\n",
    "model2 = nn.Sequential(*list(rnn_pretrain.children())[:1])\n",
    "model2.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1d500c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a86a19a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba67e6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "652\n",
      "(652, 40)\n",
      "693\n",
      "(693, 40)\n",
      "1069\n",
      "(1069, 40)\n",
      "449\n",
      "(449, 40)\n",
      "373\n",
      "(373, 40)\n",
      "550\n",
      "(550, 40)\n",
      "344\n",
      "(344, 40)\n",
      "636\n",
      "(636, 40)\n",
      "757\n",
      "(757, 40)\n",
      "763\n",
      "(763, 40)\n"
     ]
    }
   ],
   "source": [
    "import kaldiark\n",
    "\n",
    "train_bpali_file = open('./data/train-si284.bpali', 'rb')\n",
    "train_fbank_scp = open('./data/si284-0.9-train.fbank.scp', 'rb')\n",
    "train_fbank_lines = train_fbank_scp.readlines()\n",
    "\n",
    "# Train + Dev\n",
    "for i in range(1):\n",
    "    with open('./data/si284-0.9-train.bpali.scp', 'rb') as scp_file:\n",
    "        bpali_lines = scp_file.readlines()\n",
    "        for idx,line in enumerate(bpali_lines[:10]):\n",
    "            # Find the label\n",
    "            temp = str(line).split()[1]\n",
    "            pointer = temp.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the label\n",
    "            # Linux only has \\n\n",
    "            train_bpali_file.seek(int(pointer))\n",
    "            transcript = train_bpali_file.readline()\n",
    "            labels = str(transcript)[2:-3].split()\n",
    "            print(len(labels))\n",
    "\n",
    "            # Find the utterance\n",
    "            utt_line = train_fbank_lines[idx]\n",
    "            temp = str(utt_line).split()[1]\n",
    "            utt_file_loc = temp.split(':')[0][24:]  # ark file path; keep [14:]\n",
    "            utt_pointer = temp.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the utterance\n",
    "            # print(temp, utt_file_loc)\n",
    "\n",
    "            with open('./data' + utt_file_loc, 'rb') as ark_file:\n",
    "                # mlp use: '../remote/data' + utt_file_loc\n",
    "                # ubuntu use: './data' + utt_file_loc\n",
    "                ark_file.seek(int(utt_pointer))\n",
    "                utt_mat = kaldiark.parse_feat_matrix(ark_file)\n",
    "                print(utt_mat.shape)\n",
    "\n",
    "                for iidx in range(utt_mat.shape[0]):\n",
    "                    mat = utt_mat[iidx]\n",
    "                    \n",
    "#                     y = standard.index(labels[iidx])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ae58a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb6aaf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fda21467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The len of train dataset=60000\n",
      "The len of test dataset=10000\n",
      "The images size is {} torch.Size([100, 1, 28, 28])\n",
      "The labels size is torch.Size([100])\n",
      "epoch=0:idx=0,loss=2.3129\n",
      "epoch=0:idx=100,loss=0.748687\n",
      "epoch=0:idx=200,loss=0.684061\n",
      "epoch=0:idx=300,loss=0.567122\n",
      "epoch=0:idx=400,loss=0.399482\n",
      "epoch=0:idx=500,loss=0.437477\n",
      "epoch=1:idx=0,loss=0.342163\n",
      "epoch=1:idx=100,loss=0.349955\n",
      "epoch=1:idx=200,loss=0.425068\n",
      "epoch=1:idx=300,loss=0.35158\n",
      "epoch=1:idx=400,loss=0.297613\n",
      "epoch=1:idx=500,loss=0.366245\n",
      "epoch=2:idx=0,loss=0.272809\n",
      "epoch=2:idx=100,loss=0.301265\n",
      "epoch=2:idx=200,loss=0.360736\n",
      "epoch=2:idx=300,loss=0.298638\n",
      "epoch=2:idx=400,loss=0.270854\n",
      "epoch=2:idx=500,loss=0.341554\n",
      "epoch=3:idx=0,loss=0.24093\n",
      "epoch=3:idx=100,loss=0.281189\n",
      "epoch=3:idx=200,loss=0.326516\n",
      "epoch=3:idx=300,loss=0.275719\n",
      "epoch=3:idx=400,loss=0.259233\n",
      "epoch=3:idx=500,loss=0.327415\n",
      "epoch=4:idx=0,loss=0.223047\n",
      "epoch=4:idx=100,loss=0.270883\n",
      "epoch=4:idx=200,loss=0.304503\n",
      "epoch=4:idx=300,loss=0.262978\n",
      "epoch=4:idx=400,loss=0.252757\n",
      "epoch=4:idx=500,loss=0.317919\n",
      "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n",
      "        4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, 2,\n",
      "        4, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 9, 3, 7, 4, 6, 4, 3, 0, 7, 0,\n",
      "        2, 9, 1, 7, 3, 2, 9, 7, 7, 6, 2, 7, 8, 4, 7, 3, 6, 1, 3, 6, 9, 3, 1, 4,\n",
      "        1, 7, 6, 9])\n",
      "x size:torch.Size([100, 784])\n",
      "preds size:torch.Size([100, 10])\n",
      "predicted size:torch.Size([100])\n",
      "92.220000%\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets\n",
    "import torchvision.transforms\n",
    "import torch.utils.data\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn\n",
    "import torch.optim\n",
    "\n",
    "# from debug import ptf_tensor\n",
    "\n",
    "# Hyperparameters超参数\n",
    "BATCH_SIZE=100\n",
    "NUM_EPOCHS=5\n",
    "DEVICE='cpu'\n",
    "\n",
    "########################## 训练集的准备 ##############################################\n",
    "\n",
    "train_dataset=torchvision.datasets.MNIST(root='~/fyp-code/mnist',train=True,transform=torchvision.transforms.ToTensor(),download=True)\n",
    "#root:下载数据存放到哪里，train:下载训练集还是测试集，transfrom:数据转化的形式\n",
    "\n",
    "test_dataset=torchvision.datasets.MNIST(root='~/fyp-code/mnist',train=False, transform=torchvision.transforms.ToTensor(),download=True)\n",
    "\n",
    "#由于数据集里面有上万条数据，我们需要分批从数据集读取数据\n",
    "train_dataloader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=BATCH_SIZE)\n",
    "print('The len of train dataset={}'.format(len(train_dataset)))\n",
    "\n",
    "test_dataloader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=BATCH_SIZE)\n",
    "print('The len of test dataset={}'.format(len(test_dataset)))\n",
    "\n",
    "for images,labels in train_dataloader:\n",
    "    print('The images size is {}',format(images.size())) \n",
    "    print('The labels size is {}'.format(labels.size())) \n",
    "    break\n",
    "\n",
    "#plt.imshow(images[0,0],cmap=['gray'])\n",
    "#plt.title('label = {}'.format(labels[0]))\n",
    "\n",
    "\n",
    "fc=torch.nn.Linear(28*28,10) #只使用一层线性分类器\n",
    "fc.to(DEVICE)#如果用CPU去掉\n",
    "\n",
    "\n",
    "criterion=torch.nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(fc.parameters())\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for idx, (images,labels) in enumerate(train_dataloader):\n",
    "        x =images.reshape(-1,28*28)\n",
    "\n",
    "        x=x.to(DEVICE)# 如果用CPU去掉\n",
    "        labels=labels.to(DEVICE)# 如果用CPU去掉\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds=fc(x)\n",
    "        loss=criterion(preds,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if idx % 100 ==0:\n",
    "            print('epoch={}:idx={},loss={:g}'.format(epoch,idx,loss))\n",
    "\n",
    "\n",
    "correct=0\n",
    "total=0\n",
    "\n",
    "for idx,(images,labels) in enumerate(test_dataloader):\n",
    "    x =images.reshape(-1,28*28)\n",
    "    x=x.to(DEVICE)\n",
    "    labels=labels.to(DEVICE)\n",
    "\n",
    "    preds=fc(x)\n",
    "    predicted=torch.argmax(preds,dim=1) #在dim=1中选取max值的索引\n",
    "    if idx ==0:\n",
    "        print(labels)\n",
    "        print('x size:{}'.format(x.size()))\n",
    "        print('preds size:{}'.format(preds.size()))\n",
    "        print('predicted size:{}'.format(predicted.size()))\n",
    "\n",
    "    total+=labels.size(0)\n",
    "    correct+=(predicted == labels).sum().item()\n",
    "    #print('##########################\\nidx:{}\\npreds:{}\\nactual:{}\\n##########################\\n'.format(idx,predicted,labels))\n",
    "\n",
    "accuracy=correct/total\n",
    "print('{:1%}'.format(accuracy))\n",
    "\n",
    "#torch.save(fc.state_dict(), 'D:/DataTmp/mnist/tst.pth')\n",
    "#fc=torch.nn.Linear(28*28,10) #只使用一层线性分类器\n",
    "#fc.to(DEVICE)#如果用CPU去掉\n",
    "#fc.load_state_dict(torch.load('D:/DataTmp/mnist/tst.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36ad4920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dadbd02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41bc3377",
   "metadata": {},
   "source": [
    "# K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9eecfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eu_distance(a, b):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean Distance between two point\n",
    "    :param a: Starting point\n",
    "    :param b: End Point\n",
    "    :return: Euclidean Distance\n",
    "    \"\"\"\n",
    "    dist = np.sqrt(np.sum(np.square(a - b)))\n",
    "    # np.linalg.norm(a - b)  # numpy function can replace the above\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39a2b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_cluster(datapoint, centers):\n",
    "    \"\"\"\n",
    "    Assign the given datapoint to a cluster center\n",
    "    :param datapoint: a data vector\n",
    "    :return: c_index: The assigned cluster index\n",
    "    :return: dist: The clustering error (L2 distance)\n",
    "    \"\"\"\n",
    "    dists = np.array([eu_distance(c, datapoint) for c in centers])\n",
    "    c_index = np.argmin(dists)\n",
    "    dist = np.min(dists)\n",
    "    return c_index, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3db7df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0eb5ea0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 40)\n"
     ]
    }
   ],
   "source": [
    "import kaldiark\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "temp = None\n",
    "start = True\n",
    "epochs = 0\n",
    "\n",
    "for e in range(10):\n",
    "    \n",
    "    if count != 0 and (assigns == temp).all():  # satisfy the stop condition before the epochs\n",
    "        print(epochs)\n",
    "        break\n",
    "    \n",
    "    # Read the SCP file\n",
    "    with open('./data/raw_fbank_train_si284.1.scp', 'rb') as scp_file:  \n",
    "        # mlp use '../remote/data/wsj/fbank/' replace '/data/'\n",
    "        lines = scp_file.readlines()\n",
    "        for line in lines[:5]:\n",
    "            tempt = str(line).split()[1]\n",
    "            file_loc = tempt.split(':')[0][28:]  # mlp keep [18:]\n",
    "            pointer = tempt.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the utterance\n",
    "            \n",
    "            # Read the ark file to get utterance\n",
    "            with open('./data' + file_loc, 'rb') as ark_file:  \n",
    "                # use '../remote/data' + file_loc replace './data/' + file_loc\n",
    "                ark_file.seek(int(pointer))\n",
    "                utt_mat = kaldiark.parse_feat_matrix(ark_file)\n",
    "                \n",
    "                # Use model to get representations\n",
    "                # Call a function\n",
    "                #  --------------\n",
    "                #  --------------\n",
    "                #  ###############\n",
    "                \n",
    "                # Init centers: randomly pick k data from data set as centers\n",
    "                if start:  \n",
    "                    centers = np.array(random.sample(list(utt_mat), 4))  # k=4\n",
    "                    start = False\n",
    "                    print(centers.shape)\n",
    "                    \n",
    "                # Assign data to clusters\n",
    "                assigns = np.array([assign_cluster(datapoint, centers) for datapoint in utt_mat])    \n",
    "                    \n",
    "                # Update centers\n",
    "                for c_index in range(4):  # k=4\n",
    "                    data_in_c = np.array([utt_mat[i] for i in range(utt_mat.shape[0]) if assigns[i][0] == c_index])\n",
    "                    centers[c_index] = np.mean(data_in_c, axis=0)\n",
    "                    \n",
    "                # Calculate the clustering loss\n",
    "                \n",
    "                    \n",
    "                temp = assigns  # store the old assigns\n",
    "    epochs += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bb4355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5860caa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(652, 40)\n",
      "(693, 40)\n",
      "(1069, 40)\n",
      "(449, 40)\n",
      "(373, 40)\n",
      "(550, 40)\n",
      "(344, 40)\n",
      "(636, 40)\n",
      "(757, 40)\n",
      "(763, 40)\n",
      "(924, 40)\n"
     ]
    }
   ],
   "source": [
    "# Read the utterance from the file\n",
    "\n",
    "import kaldiark\n",
    "\n",
    "# Read data index from the total scp file\n",
    "\n",
    "count = 0\n",
    "\n",
    "with open('./data/raw_fbank_train_si284.1.scp', 'rb') as scp_file:  \n",
    "    # mlp use '../remote/data/wsj/fbank/' replace '/data/'\n",
    "    lines = scp_file.readlines()\n",
    "    for line in lines:\n",
    "        temp = str(line).split()[1]\n",
    "        file_loc = temp.split(':')[0][28:]  # mlp keep [18:]\n",
    "        pointer = temp.split(':')[1][:-3].replace('\\\\r', '')  # pointer to the utterance\n",
    "\n",
    "        # According to the file name and pointer to get the matrix\n",
    "        with open('./data' + file_loc, 'rb') as ark_file:  \n",
    "            # use '../remote/data' + file_loc replace './data/' + file_loc\n",
    "            ark_file.seek(int(pointer))\n",
    "            utt_mat = kaldiark.parse_feat_matrix(ark_file)\n",
    "            \n",
    "            # Use pre-trained model to get the extracted feature\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            print(utt_mat.shape)  \n",
    "        \n",
    "        count = count + 1\n",
    "        if count > 10:\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abb76b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f8ff34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee7c4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066ddc8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc4c1f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
